\babel@toc {italian}{}\relax 
\babel@toc {italian}{}\relax 
\contentsline {part}{I\hspace {1em}Concetti Preliminari}{1}{part.1}%
\contentsline {chapter}{\numberline {1}Prerequisiti Matematici Essenziali [WIP]}{3}{chapter.1}%
\contentsline {chapter}{\numberline {2}Grafi}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}Definizione formale}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Network science}{6}{subsection.2.1.1}%
\contentsline {section}{\numberline {2.2}Grafi diretti e indiretti}{6}{section.2.2}%
\contentsline {paragraph}{Come capire che tipologia usare.}{6}{section*.4}%
\contentsline {section}{\numberline {2.3}Grafi pesati e grafi etichettati}{7}{section.2.3}%
\contentsline {section}{\numberline {2.4}Gradi dei vertici}{7}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Distribuzione dei gradi}{8}{subsection.2.4.1}%
\contentsline {section}{\numberline {2.5}Grafi bipartiti}{8}{section.2.5}%
\contentsline {paragraph}{Generalizzazione.}{9}{section*.7}%
\contentsline {section}{\numberline {2.6}Grafo completo vs Grafo regolare}{9}{section.2.6}%
\contentsline {section}{\numberline {2.7}Cammini tra due nodi}{9}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}Cammino minimo}{9}{subsection.2.7.1}%
\contentsline {subsection}{\numberline {2.7.2}Diametro}{10}{subsection.2.7.2}%
\contentsline {subsection}{\numberline {2.7.3}Ciclo}{10}{subsection.2.7.3}%
\contentsline {paragraph}{Cappio.}{10}{section*.10}%
\contentsline {section}{\numberline {2.8}Connettività}{10}{section.2.8}%
\contentsline {subsection}{\numberline {2.8.1}Connettività forte e debole}{11}{subsection.2.8.1}%
\contentsline {section}{\numberline {2.9}Coefficiente di Clustering}{11}{section.2.9}%
\contentsline {paragraph}{Clustering medio.}{12}{section*.12}%
\contentsline {paragraph}{Coefficiente di clustering globale.}{12}{section*.13}%
\contentsline {section}{\numberline {2.10}Misure di centralità}{12}{section.2.10}%
\contentsline {subsection}{\numberline {2.10.1}Centralità di grado}{12}{subsection.2.10.1}%
\contentsline {subsection}{\numberline {2.10.2}Centralità di vicinanza}{12}{subsection.2.10.2}%
\contentsline {paragraph}{Esempio (nodo \(3\)).}{13}{section*.15}%
\contentsline {subsection}{\numberline {2.10.3}Centralità di prossimità}{14}{subsection.2.10.3}%
\contentsline {subsection}{\numberline {2.10.4}Centralità di PageRank}{14}{subsection.2.10.4}%
\contentsline {paragraph}{Esempio.}{15}{section*.17}%
\contentsline {part}{II\hspace {1em}Tecniche di Data Mining}{17}{part.2}%
\contentsline {chapter}{\numberline {3}Introduzione al Data Mining}{19}{chapter.3}%
\contentsline {section}{\numberline {3.1}Definizione e finalità}{19}{section.3.1}%
\contentsline {section}{\numberline {3.2}Caratteristiche dei pattern}{19}{section.3.2}%
\contentsline {section}{\numberline {3.3}Metodi di data mining}{19}{section.3.3}%
\contentsline {section}{\numberline {3.4}Perché fare data mining}{20}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Big Data}{20}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Dai dati alla conoscenza e alle comunità coinvolte}{20}{subsection.3.4.2}%
\contentsline {section}{\numberline {3.5}Limiti e insidie del data mining}{20}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Caso di studio: Total Information Awareness (TIA)}{20}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Esempio: co-presenza in hotel come criterio di sospetto}{21}{subsection.3.5.2}%
\contentsline {paragraph}{Dati di partenza.}{21}{section*.21}%
\contentsline {paragraph}{Ipotesi nulla (random).}{21}{section*.22}%
\contentsline {paragraph}{Calcoli numerici.}{21}{section*.23}%
\contentsline {paragraph}{Considerazioni.}{21}{section*.24}%
\contentsline {section}{\numberline {3.6}Principio di Bonferroni e test multipli}{22}{section.3.6}%
\contentsline {paragraph}{Interpretazione operativa.}{22}{section*.25}%
\contentsline {paragraph}{Quando applicarlo.}{22}{section*.26}%
\contentsline {chapter}{\numberline {4}Preprocessing}{23}{chapter.4}%
\contentsline {section}{\numberline {4.1}Estrazione di feature}{23}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Tecniche di estrazione di feature}{24}{subsection.4.1.1}%
\contentsline {section}{\numberline {4.2}Portabilità dei dati}{24}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Da dati numerici a categorici}{24}{subsection.4.2.1}%
\contentsline {paragraph}{Equi-width ranges.}{24}{section*.27}%
\contentsline {paragraph}{Equi-log ranges.}{24}{section*.28}%
\contentsline {paragraph}{Equi-depth ranges.}{24}{section*.29}%
\contentsline {subsection}{\numberline {4.2.2}Da dati categorici a numerici}{25}{subsection.4.2.2}%
\contentsline {paragraph}{One-hot encoding.}{25}{section*.30}%
\contentsline {subsection}{\numberline {4.2.3}Da testo a dati numerici}{25}{subsection.4.2.3}%
\contentsline {section}{\numberline {4.3}Cleaning dei dati}{25}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Gestione dei valori mancanti}{25}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Gestione dei valori errati}{26}{subsection.4.3.2}%
\contentsline {paragraph}{Quantili.}{26}{section*.31}%
\contentsline {subsection}{\numberline {4.3.3}Scala dei dati}{26}{subsection.4.3.3}%
\contentsline {paragraph}{Standardizzazione.}{27}{section*.32}%
\contentsline {paragraph}{Min-Max scaling.}{27}{section*.33}%
\contentsline {section}{\numberline {4.4}Riduzione dei dati}{27}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Sampling dei dati}{27}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Selezione di feature}{28}{subsection.4.4.2}%
\contentsline {subsection}{\numberline {4.4.3}Riduzione della dimensionalità}{28}{subsection.4.4.3}%
\contentsline {subsection}{\numberline {4.4.4}PCA: Principal Component Analysis}{28}{subsection.4.4.4}%
\contentsline {subsection}{\numberline {4.4.5}SVD: Singular Value Decomposition}{30}{subsection.4.4.5}%
\contentsline {paragraph}{Interpretazione geometrica.}{30}{section*.34}%
\contentsline {paragraph}{Varianti ridotte della SVD.}{30}{section*.35}%
\contentsline {paragraph}{SVD vs PCA.}{31}{section*.37}%
\contentsline {subsection}{\numberline {4.4.6}LSA: Latent Semantic Analysis}{32}{subsection.4.4.6}%
\contentsline {subsection}{\numberline {4.4.7}Riduzione di dimensionalità con trasformazione dei dati}{32}{subsection.4.4.7}%
\contentsline {paragraph}{Esempio: serie temporali.}{32}{section*.38}%
\contentsline {chapter}{\numberline {5}Insiemi Frequenti e Regole d'Associazione}{33}{chapter.5}%
\contentsline {section}{\numberline {5.1}Market-basket model e definizioni}{33}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Supporto}{33}{subsection.5.1.1}%
\contentsline {paragraph}{Soglia di supporto: trade-off.}{33}{section*.39}%
\contentsline {section}{\numberline {5.2}Regole d'associazione}{33}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Qualità di una regola}{34}{subsection.5.2.1}%
\contentsline {paragraph}{Confidenza.}{34}{section*.40}%
\contentsline {paragraph}{Coverage.}{34}{section*.41}%
\contentsline {paragraph}{Interesse.}{34}{section*.42}%
\contentsline {paragraph}{Lift.}{34}{section*.43}%
\contentsline {paragraph}{Nota.}{34}{section*.44}%
\contentsline {paragraph}{Mini-esempio (toy dataset).}{34}{section*.45}%
\contentsline {section}{\numberline {5.3}Insiemi frequenti chiusi e massimali}{34}{section.5.3}%
\contentsline {section}{\numberline {5.4}Anti-monotonia e Principio di Apriori}{35}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Principio di Apriori}{35}{subsection.5.4.1}%
\contentsline {section}{\numberline {5.5}Algoritmo Apriori}{35}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}Esempio Apriori (minsup = 2)}{36}{subsection.5.5.1}%
\contentsline {paragraph}{$k=1\!\to \!2$: generazione $C_2$ e conteggi.}{36}{section*.47}%
\contentsline {paragraph}{$k=2\!\to \!3$: self-join e prune.}{36}{section*.48}%
\contentsline {subsection}{\numberline {5.5.2}Generazione dei candidati}{36}{subsection.5.5.2}%
\contentsline {section}{\numberline {5.6}Ottimizzazioni di Apriori}{36}{section.5.6}%
\contentsline {subsection}{\numberline {5.6.1}Hashing in bucket: PCY}{36}{subsection.5.6.1}%
\contentsline {paragraph}{Varianti multistadio e multihash.}{37}{section*.49}%
\contentsline {subsection}{\numberline {5.6.2}Partizionamento del DB: SON}{37}{subsection.5.6.2}%
\contentsline {subsection}{\numberline {5.6.3}Campionamento e frontiera negativa: Toivonen}{37}{subsection.5.6.3}%
\contentsline {section}{\numberline {5.7}Perch\'e andare oltre Apriori}{37}{section.5.7}%
\contentsline {section}{\numberline {5.8}FP-Growth: idea di base}{37}{section.5.8}%
\contentsline {subsection}{\numberline {5.8.1}Costruzione dell'FP-tree}{37}{subsection.5.8.1}%
\contentsline {subsection}{\numberline {5.8.2}Esempio di FP-Growth}{38}{subsection.5.8.2}%
\contentsline {paragraph}{Visita per pattern-growth.}{38}{section*.51}%
\contentsline {paragraph}{Espansione di un item $x$.}{38}{section*.52}%
\contentsline {paragraph}{Esempio 1: item $p$.}{39}{section*.54}%
\contentsline {paragraph}{Esempio 2: item $m$.}{39}{section*.55}%
\contentsline {paragraph}{Esempio 3: item $b$.}{39}{section*.56}%
\contentsline {section}{\numberline {5.9}Confronto: FP-Growth vs Apriori}{39}{section.5.9}%
\contentsline {chapter}{\numberline {6}Clustering}{41}{chapter.6}%
\contentsline {section}{\numberline {6.1}Spazi metrici e distanze}{41}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Spazio euclideo}{41}{subsection.6.1.1}%
\contentsline {paragraph}{Centroide.}{42}{section*.58}%
\contentsline {subsection}{\numberline {6.1.2}Spazi non euclidei}{42}{subsection.6.1.2}%
\contentsline {section}{\numberline {6.2}Algoritmi di clustering}{43}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Tipi di clustering}{43}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Bontà di un algoritmo}{43}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Curse of dimensionality}{44}{subsection.6.2.3}%
\contentsline {subsection}{\numberline {6.2.4}Ortogonalità dei vettori}{44}{subsection.6.2.4}%
\contentsline {section}{\numberline {6.3}Clustering Gerarchico}{45}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Distanze tra cluster}{45}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Dendrogramma}{45}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Clustering divisivo}{47}{subsection.6.3.3}%
\contentsline {subsection}{\numberline {6.3.4}Complessità computazionale}{47}{subsection.6.3.4}%
\contentsline {section}{\numberline {6.4}Clustering partizionale: K-means}{47}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Scelta greedy dei centroidi iniziali}{48}{subsection.6.4.1}%
\contentsline {subsection}{\numberline {6.4.2}Funzione obiettivo}{48}{subsection.6.4.2}%
\contentsline {subsection}{\numberline {6.4.3}Scelta del numero di cluster}{48}{subsection.6.4.3}%
\contentsline {paragraph}{Metodo elbow.}{48}{section*.61}%
\contentsline {paragraph}{Metodo silhouette.}{49}{section*.63}%
\contentsline {subsection}{\numberline {6.4.4}Complessità computazionale}{50}{subsection.6.4.4}%
\contentsline {subsection}{\numberline {6.4.5}K-means su Big data}{51}{subsection.6.4.5}%
\contentsline {section}{\numberline {6.5}Clustering per densità: DBSCAN}{51}{section.6.5}%
\contentsline {subsection}{\numberline {6.5.1}DBSCAN}{51}{subsection.6.5.1}%
\contentsline {paragraph}{Definizione di cluster in DBSCAN.}{51}{section*.65}%
\contentsline {paragraph}{Algoritmo DBSCAN.}{52}{section*.66}%
\contentsline {paragraph}{Complessità computazionale.}{53}{section*.68}%
\contentsline {subsection}{\numberline {6.5.2}OPTICS}{53}{subsection.6.5.2}%
\contentsline {paragraph}{Distanza di raggiungibilità e area localizzata.}{53}{section*.69}%
\contentsline {paragraph}{Reachability plot.}{54}{section*.70}%
\contentsline {paragraph}{Estrazione dei cluster.}{54}{section*.72}%
\contentsline {paragraph}{Complessità computazionale.}{56}{section*.74}%
\contentsline {subsection}{\numberline {6.5.3}HDBSCAN}{56}{subsection.6.5.3}%
\contentsline {paragraph}{Cluster in HDBSCAN.}{56}{section*.76}%
\contentsline {paragraph}{Estrazione dei cluster stabili.}{57}{section*.77}%
\contentsline {chapter}{\numberline {7}Classificazione}{59}{chapter.7}%
\contentsline {section}{\numberline {7.1}Introduzione}{59}{section.7.1}%
\contentsline {paragraph}{Predizione (regressione).}{59}{section*.79}%
\contentsline {subsection}{\numberline {7.1.1}Schema generale di un classificatore}{59}{subsection.7.1.1}%
\contentsline {paragraph}{Overfitting.}{59}{section*.80}%
\contentsline {subsection}{\numberline {7.1.2}Requisiti desiderabili}{59}{subsection.7.1.2}%
\contentsline {section}{\numberline {7.2}Alberi decisionali}{60}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}Classificazione tramite albero}{60}{subsection.7.2.1}%
\contentsline {subsection}{\numberline {7.2.2}Costruzione top–down}{60}{subsection.7.2.2}%
\contentsline {paragraph}{Pruning.}{61}{section*.83}%
\contentsline {subsection}{\numberline {7.2.3}Splitting degli attributi}{61}{subsection.7.2.3}%
\contentsline {subsection}{\numberline {7.2.4}Scelta dell’attributo e strategia greedy}{61}{subsection.7.2.4}%
\contentsline {section}{\numberline {7.3}Misure di goodness}{61}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}Information Gain (ID3)}{61}{subsection.7.3.1}%
\contentsline {paragraph}{Idea.}{61}{section*.84}%
\contentsline {paragraph}{Limite noto.}{62}{section*.86}%
\contentsline {subsection}{\numberline {7.3.2}Gain Ratio (C4.5)}{62}{subsection.7.3.2}%
\contentsline {paragraph}{Selezione in C4.5.}{63}{section*.88}%
\contentsline {paragraph}{Nota pratica (attributi continui).}{63}{section*.89}%
\contentsline {subsection}{\numberline {7.3.3}Gini Index (CART)}{63}{subsection.7.3.3}%
\contentsline {subsection}{\numberline {7.3.4}Pruning degli alberi}{63}{subsection.7.3.4}%
\contentsline {paragraph}{Che cosa misurano.}{64}{section*.91}%
\contentsline {paragraph}{Decisione di pruning.}{64}{section*.92}%
\contentsline {paragraph}{Errore prima e dopo lo split.}{65}{section*.94}%
\contentsline {paragraph}{Indice di costo–complessità per lo split.}{65}{section*.95}%
\contentsline {paragraph}{Pro/contro degli alberi decisionali.}{65}{section*.97}%
\contentsline {section}{\numberline {7.4}Classificatori generativi}{65}{section.7.4}%
\contentsline {subsection}{\numberline {7.4.1}Teorema di Bayes e regola di decisione}{66}{subsection.7.4.1}%
\contentsline {subsection}{\numberline {7.4.2}Naive Bayes}{66}{subsection.7.4.2}%
\contentsline {paragraph}{Idea.}{66}{section*.98}%
\contentsline {paragraph}{Regola di decisione (MAP, in scala logaritmica).}{66}{section*.99}%
\contentsline {paragraph}{Stima essenziale delle probabilità.}{66}{section*.100}%
\contentsline {paragraph}{Vantaggi e svantaggi.}{66}{section*.101}%
\contentsline {subsection}{\numberline {7.4.3}Reti Bayesiane}{67}{subsection.7.4.3}%
\contentsline {paragraph}{Uso per la classificazione.}{67}{section*.103}%
\contentsline {section}{\numberline {7.5}Classificatori discriminativi}{67}{section.7.5}%
\contentsline {subsection}{\numberline {7.5.1}Classificazione lineare e non lineare}{68}{subsection.7.5.1}%
\contentsline {subsection}{\numberline {7.5.2}Perceptron}{68}{subsection.7.5.2}%
\contentsline {paragraph}{Definizione.}{68}{section*.104}%
\contentsline {paragraph}{Regola di aggiornamento.}{68}{section*.105}%
\contentsline {paragraph}{Proprietà.}{68}{section*.106}%
\contentsline {paragraph}{Algoritmo.}{68}{section*.107}%
\contentsline {paragraph}{One–Vs–One (OVO).}{69}{section*.108}%
\contentsline {paragraph}{One–Vs–All (OVA).}{69}{section*.109}%
\contentsline {subsection}{\numberline {7.5.3}Support Vector Machines (SVM)}{70}{subsection.7.5.3}%
\contentsline {paragraph}{Formulazione del problema.}{70}{section*.111}%
\contentsline {paragraph}{SVM Soft margin.}{72}{section*.113}%
\contentsline {paragraph}{Kernel Trick.}{73}{section*.114}%
\contentsline {paragraph}{SVM Multi-classe.}{74}{section*.115}%
\contentsline {section}{\numberline {7.6}Apprendimento Lazy}{74}{section.7.6}%
\contentsline {subsection}{\numberline {7.6.1}K-Nearest Neighbor}{74}{subsection.7.6.1}%
\contentsline {paragraph}{Algoritmo.}{75}{section*.117}%
\contentsline {paragraph}{Varianti.}{75}{section*.118}%
\contentsline {section}{\numberline {7.7}Ensemble Learning}{75}{section.7.7}%
\contentsline {subsection}{\numberline {7.7.1}Bagging}{75}{subsection.7.7.1}%
\contentsline {paragraph}{Algoritmo.}{75}{section*.119}%
\contentsline {paragraph}{Random Forest.}{75}{section*.120}%
\contentsline {subsection}{\numberline {7.7.2}Boosting}{76}{subsection.7.7.2}%
\contentsline {paragraph}{Algoritmo.}{76}{section*.122}%
\contentsline {subsection}{\numberline {7.7.3}Adaboost}{77}{subsection.7.7.3}%
\contentsline {paragraph}{Gini Index Pesato.}{77}{section*.124}%
\contentsline {paragraph}{Peso dello stump.}{78}{section*.125}%
\contentsline {paragraph}{Aggiornamento dei pesi.}{78}{section*.126}%
\contentsline {section}{\numberline {7.8}Validazione di un classificatore}{79}{section.7.8}%
\contentsline {subsection}{\numberline {7.8.1}Matrice di confusione}{79}{subsection.7.8.1}%
\contentsline {paragraph}{Misure di accuratezza con due classi.}{79}{section*.130}%
\contentsline {paragraph}{Misure di accuratezza (due classi).}{79}{section*.131}%
\contentsline {subsection}{\numberline {7.8.2}Soglia discriminativa in un classificatore binario}{80}{subsection.7.8.2}%
\contentsline {subsection}{\numberline {7.8.3}Curva ROC}{80}{subsection.7.8.3}%
\contentsline {subsection}{\numberline {7.8.4}Curva di Precision-Recall}{80}{subsection.7.8.4}%
\contentsline {subsection}{\numberline {7.8.5}Validazione di un classificatore}{81}{subsection.7.8.5}%
\contentsline {chapter}{\numberline {8}Cenni di Regressione}{83}{chapter.8}%
\contentsline {section}{\numberline {8.1}Regressione lineare semplice}{83}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}Formulazione del modello}{83}{subsection.8.1.1}%
\contentsline {subsection}{\numberline {8.1.2}Stima dei parametri}{84}{subsection.8.1.2}%
\contentsline {subsection}{\numberline {8.1.3}Interpretazione geoemetrica}{84}{subsection.8.1.3}%
\contentsline {section}{\numberline {8.2}Regressione lineare multipla}{84}{section.8.2}%
\contentsline {subsection}{\numberline {8.2.1}Formulazione del modello}{84}{subsection.8.2.1}%
\contentsline {subsection}{\numberline {8.2.2}Stima dei parametri}{85}{subsection.8.2.2}%
\contentsline {subsection}{\numberline {8.2.3}Interpretazione geometrica}{85}{subsection.8.2.3}%
\contentsline {section}{\numberline {8.3}Regressione non lineare}{85}{section.8.3}%
\contentsline {section}{\numberline {8.4}Regressione logistica}{85}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Regressione logistica binaria semplice}{86}{subsection.8.4.1}%
\contentsline {paragraph}{Stima dei parametri.}{86}{section*.133}%
\contentsline {chapter}{\numberline {9}Subgraph Matching}{87}{chapter.9}%
\contentsline {section}{\numberline {9.1}Isomorfismo di Grafi}{87}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}Automorfismo}{87}{subsection.9.1.1}%
\contentsline {section}{\numberline {9.2}Operazione di subgraph matching}{88}{section.9.2}%
\contentsline {section}{\numberline {9.3}Complessità computazionale}{89}{section.9.3}%
\contentsline {section}{\numberline {9.4}Algoritmi di subgraph matching}{89}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Soluzione Bruteforce}{89}{subsection.9.4.1}%
\contentsline {paragraph}{Esempio di backtracking.}{90}{section*.139}%
\contentsline {subsection}{\numberline {9.4.2}Algoritmo di Ullmann}{90}{subsection.9.4.2}%
\contentsline {paragraph}{Esempio della figura \ref {fig:ullmann_algorithm_example}.}{91}{section*.142}%
\contentsline {subsection}{\numberline {9.4.3}Algoritmo VF}{91}{subsection.9.4.3}%
\contentsline {paragraph}{Algoritmo.}{92}{section*.143}%
\contentsline {paragraph}{Regola di fattibilità per grafi indiretti.}{92}{section*.144}%
\contentsline {paragraph}{Regola di fattibilità per grafi diretti.}{92}{section*.146}%
\contentsline {paragraph}{Complessità e considerazioni}{94}{section*.147}%
\contentsline {subsection}{\numberline {9.4.4}Algoritmo VF2}{94}{subsection.9.4.4}%
\contentsline {subsection}{\numberline {9.4.5}Algoritmo RI}{95}{subsection.9.4.5}%
\contentsline {paragraph}{Ordinamento dei nodi.}{95}{section*.148}%
\contentsline {paragraph}{Passo $i=1$.}{96}{section*.151}%
\contentsline {paragraph}{Passo $i=2$.}{96}{section*.152}%
\contentsline {paragraph}{Tabella finale}{97}{section*.154}%
\contentsline {subsection}{\numberline {9.4.6}RI-DS}{97}{subsection.9.4.6}%
\contentsline {section}{\numberline {9.5}Subgraph Matching in Database di Grafi}{97}{section.9.5}%
\contentsline {subsection}{\numberline {9.5.1}Indicizzazione}{98}{subsection.9.5.1}%
\contentsline {section}{\numberline {9.6}Features dei grafi}{98}{section.9.6}%
\contentsline {paragraph}{Esempio di filtraggio tramite profili di feature.}{98}{figure.caption.156}%
\contentsline {subsection}{\numberline {9.6.1}Schema di subgraph matching in database di grafi}{99}{subsection.9.6.1}%
\contentsline {subsection}{\numberline {9.6.2}Indicizzazione inversa}{100}{subsection.9.6.2}%
\contentsline {subsection}{\numberline {9.6.3}Algoritmo SING}{100}{subsection.9.6.3}%
\contentsline {paragraph}{Processamento della query.}{100}{section*.159}%
\contentsline {chapter}{\numberline {10}Subgraph Matching di Grafi Frequenti}{103}{chapter.10}%
\contentsline {section}{\numberline {10.1}Algoritmo FSG}{104}{section.10.1}%
\contentsline {subsection}{\numberline {10.1.1}Regola Apriori per sotto-grafi}{104}{subsection.10.1.1}%
\contentsline {subsection}{\numberline {10.1.2}Join tra sotto-grafi}{105}{subsection.10.1.2}%
\contentsline {paragraph}{Scenario 1: i due sottografi differiscono per un nodo.}{105}{figure.caption.164}%
\contentsline {paragraph}{Scenario 2: il grafo \emph {core} ha più automorfismi.}{105}{figure.caption.166}%
\contentsline {paragraph}{Scenario 3: i sottografi candidati hanno più grafi \emph {core} in comune.}{106}{figure.caption.168}%
\contentsline {paragraph}{Caso generale.}{108}{section*.169}%
\contentsline {subsection}{\numberline {10.1.3}Procedura dell'algoritmo}{108}{subsection.10.1.3}%
\contentsline {subsection}{\numberline {10.1.4}Generazione dei candidati}{108}{subsection.10.1.4}%
\contentsline {subsection}{\numberline {10.1.5}Stringa di adiacenza}{109}{subsection.10.1.5}%
\contentsline {subsection}{\numberline {10.1.6}Forma canonica}{109}{subsection.10.1.6}%
\contentsline {paragraph}{Algoritmo.}{109}{section*.171}%
\contentsline {paragraph}{Esempio.}{109}{section*.172}%
\contentsline {subsection}{\numberline {10.1.7}Verifica della regola Apriori}{110}{subsection.10.1.7}%
\contentsline {section}{\numberline {10.2}Algoritmo gSpan}{111}{section.10.2}%
\contentsline {subsection}{\numberline {10.2.1}Visita DFS}{111}{subsection.10.2.1}%
\contentsline {paragraph}{Albero DFS.}{111}{section*.175}%
\contentsline {subsection}{\numberline {10.2.2}Codifica DFS}{111}{subsection.10.2.2}%
\contentsline {paragraph}{Costruzione della codifica DFS.}{113}{section*.177}%
\contentsline {paragraph}{Codice DFS minimo.}{113}{section*.179}%
\contentsline {paragraph}{DFS Code Tree.}{113}{section*.180}%
\contentsline {subsection}{\numberline {10.2.3}Generazione dei candidati}{114}{subsection.10.2.3}%
\contentsline {paragraph}{Pruning dello spazio di ricerca.}{115}{section*.182}%
\contentsline {chapter}{\numberline {11}Elementi di Reti neurali}{117}{chapter.11}%
\contentsline {section}{\numberline {11.1}Strati}{118}{section.11.1}%
\contentsline {paragraph}{Deep neural network.}{118}{section*.186}%
\contentsline {subsection}{\numberline {11.1.1}Connessioni tra layer}{119}{subsection.11.1.1}%
\contentsline {section}{\numberline {11.2}Progettare una rete neurale}{119}{section.11.2}%
\contentsline {section}{\numberline {11.3}Funzioni di attivazione}{119}{section.11.3}%
\contentsline {paragraph}{Proprietà.}{120}{section*.187}%
\contentsline {subsection}{\numberline {11.3.1}Funzione step}{120}{subsection.11.3.1}%
\contentsline {subsection}{\numberline {11.3.2}Funzione logistica}{121}{subsection.11.3.2}%
\contentsline {subsection}{\numberline {11.3.3}Tangente iperbolica}{122}{subsection.11.3.3}%
\contentsline {subsection}{\numberline {11.3.4}Funzione softmax}{122}{subsection.11.3.4}%
\contentsline {subsection}{\numberline {11.3.5}ReLU: Rectified Linear Unit}{123}{subsection.11.3.5}%
\contentsline {paragraph}{Variante ELU.}{124}{section*.192}%
\contentsline {section}{\numberline {11.4}Funzioni Loss}{124}{section.11.4}%
\contentsline {subsection}{\numberline {11.4.1}Regression Loss}{124}{subsection.11.4.1}%
\contentsline {paragraph}{MSE: Mean Squared Error.}{125}{section*.195}%
\contentsline {subsection}{\numberline {11.4.2}Classification Loss}{126}{subsection.11.4.2}%
\contentsline {paragraph}{Entropia.}{126}{section*.196}%
\contentsline {paragraph}{Entropia incrociata.}{126}{section*.197}%
\contentsline {section}{\numberline {11.5}Training di una rete neurale}{127}{section.11.5}%
\contentsline {subsection}{\numberline {11.5.1}Ottimizzazione dei pesi}{127}{subsection.11.5.1}%
\contentsline {subsection}{\numberline {11.5.2}Metodo di discesa del gradiente}{127}{subsection.11.5.2}%
\contentsline {paragraph}{Matrice Jacobiana.}{129}{section*.199}%
\contentsline {paragraph}{Stochastic Gradient Descent.}{129}{section*.200}%
\contentsline {subsection}{\numberline {11.5.3}Esempio di computazione}{129}{subsection.11.5.3}%
\contentsline {subsection}{\numberline {11.5.4}Backpropagation}{130}{subsection.11.5.4}%
\contentsline {paragraph}{Regola della catena.}{130}{section*.202}%
\contentsline {paragraph}{Esempio.}{131}{section*.203}%
\contentsline {section}{\numberline {11.6}Tecniche di Regolarizzazione}{133}{section.11.6}%
\contentsline {subsection}{\numberline {11.6.1}Regolarizzazione L1 e L2}{133}{subsection.11.6.1}%
\contentsline {subsection}{\numberline {11.6.2}Dropout}{134}{subsection.11.6.2}%
\contentsline {subsection}{\numberline {11.6.3}Early Stopping}{134}{subsection.11.6.3}%
\contentsline {subsection}{\numberline {11.6.4}Aumento del training set}{134}{subsection.11.6.4}%
\contentsline {section}{\numberline {11.7}Tipi di reti neurali}{135}{section.11.7}%
\contentsline {subsection}{\numberline {11.7.1}Feed-Forward Networks}{135}{subsection.11.7.1}%
\contentsline {subsection}{\numberline {11.7.2}Reti Neurali Convoluzionali}{135}{subsection.11.7.2}%
\contentsline {paragraph}{Fotorecettori.}{136}{section*.207}%
\contentsline {paragraph}{Convolutional Layer.}{136}{section*.208}%
\contentsline {paragraph}{Stride.}{136}{section*.209}%
\contentsline {paragraph}{Zero Padding.}{136}{section*.210}%
\contentsline {paragraph}{Pooling Layer.}{136}{section*.211}%
\contentsline {paragraph}{CNN su immagini a colori.}{137}{section*.212}%
\contentsline {subsection}{\numberline {11.7.3}Rete neurali di grafi}{137}{subsection.11.7.3}%
\contentsline {subsection}{\numberline {11.7.4}Reti Neurali Ricorrenti}{138}{subsection.11.7.4}%
\contentsline {paragraph}{Input di una RNN.}{138}{section*.215}%
\contentsline {subsection}{\numberline {11.7.5}LSTM: Long Short-Term Memory}{139}{subsection.11.7.5}%
\contentsline {paragraph}{Aggiornamento della cella di memoria.}{140}{section*.217}%
\contentsline {subsection}{\numberline {11.7.6}Autoencoder}{142}{subsection.11.7.6}%
\contentsline {paragraph}{Varianti di autoencoder.}{142}{section*.218}%
\contentsline {subsection}{\numberline {11.7.7}Variational Autoencoder}{142}{subsection.11.7.7}%
\contentsline {paragraph}{Loss function dei VAE.}{143}{section*.219}%
\contentsline {paragraph}{Applicazione di VAE.}{143}{section*.220}%
\contentsline {chapter}{\numberline {12}Introduzione a Transformer e LLM}{145}{chapter.12}%
\contentsline {section}{\numberline {12.1}Transformer}{145}{section.12.1}%
\contentsline {subsection}{\numberline {12.1.1}Seq2seq}{145}{subsection.12.1.1}%
\contentsline {paragraph}{Limitazioni delle RNN.}{145}{section*.223}%
\contentsline {part}{III\hspace {1em}Approfondimenti}{147}{part.3}%
