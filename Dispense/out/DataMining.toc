\babel@toc {italian}{}\relax 
\babel@toc {italian}{}\relax 
\contentsline {chapter}{\numberline {1}Prerequisiti Matematici Essenziali}{1}{chapter.1}%
\contentsline {section}{\numberline {1.1}Orientamento e notazione}{1}{section.1.1}%
\contentsline {section}{\numberline {1.2}Vettori e matrici}{1}{section.1.2}%
\contentsline {subsection}{\numberline {1.2.1}Combinazioni lineari e prodotto matrice–vettore}{1}{subsection.1.2.1}%
\contentsline {paragraph}{Esempio.}{1}{section*.2}%
\contentsline {subsection}{\numberline {1.2.2}Prodotto matrice–matrice}{1}{subsection.1.2.2}%
\contentsline {paragraph}{Esempio.}{1}{section*.3}%
\contentsline {section}{\numberline {1.3}Distanze e similarità}{2}{section.1.3}%
\contentsline {subsection}{\numberline {1.3.1}Norme classiche}{2}{subsection.1.3.1}%
\contentsline {paragraph}{Esempio.}{2}{section*.4}%
\contentsline {subsection}{\numberline {1.3.2}Prodotto scalare e angolo}{2}{subsection.1.3.2}%
\contentsline {paragraph}{Esempio (cosine).}{2}{section*.5}%
\contentsline {subsection}{\numberline {1.3.3}Jaccard per insiemi}{2}{subsection.1.3.3}%
\contentsline {section}{\numberline {1.4}Sottospazi, basi e rango}{2}{section.1.4}%
\contentsline {paragraph}{Rango.}{2}{section*.6}%
\contentsline {paragraph}{Esempio.}{2}{section*.7}%
\contentsline {section}{\numberline {1.5}Proiezioni ortogonali e minimi quadrati}{2}{section.1.5}%
\contentsline {subsection}{\numberline {1.5.1}Proiezione su una direzione}{2}{subsection.1.5.1}%
\contentsline {paragraph}{Esempio (retta \(y=x\)).}{2}{section*.8}%
\contentsline {subsection}{\numberline {1.5.2}Minimi quadrati in due righe}{2}{subsection.1.5.2}%
\contentsline {paragraph}{Esempio.}{3}{section*.9}%
\contentsline {section}{\numberline {1.6}Autovalori e autovettori}{3}{section.1.6}%
\contentsline {paragraph}{Esempio.}{3}{section*.10}%
\contentsline {section}{\numberline {1.7}Probabilità e statistica}{3}{section.1.7}%
\contentsline {subsection}{\numberline {1.7.1}Attesa e varianza}{3}{subsection.1.7.1}%
\contentsline {paragraph}{Esempio.}{3}{section*.11}%
\contentsline {subsection}{\numberline {1.7.2}Covarianza e correlazione}{3}{subsection.1.7.2}%
\contentsline {paragraph}{Matrice di covarianza (dati centrati).}{3}{section*.12}%
\contentsline {paragraph}{Esempio.}{3}{section*.13}%
\contentsline {subsection}{\numberline {1.7.3}Quantili e IQR}{3}{subsection.1.7.3}%
\contentsline {paragraph}{Esempio.}{3}{section*.14}%
\contentsline {subsection}{\numberline {1.7.4}Modello di Bayes e tipi di probabilità}{3}{subsection.1.7.4}%
\contentsline {paragraph}{Tipi di probabilità.}{4}{section*.15}%
\contentsline {paragraph}{Teorema di Bayes.}{4}{section*.16}%
\contentsline {section}{\numberline {1.8}Preprocessing numerico}{4}{section.1.8}%
\contentsline {paragraph}{Standardizzazione (z-score).}{4}{section*.17}%
\contentsline {paragraph}{Min--max scaling.}{4}{section*.18}%
\contentsline {paragraph}{Robust scaling.}{4}{section*.19}%
\contentsline {paragraph}{Codifiche categoriali.}{4}{section*.20}%
\contentsline {paragraph}{Esempio.}{4}{section*.21}%
\contentsline {section}{\numberline {1.9}Combinatoria utile}{4}{section.1.9}%
\contentsline {paragraph}{Coefficienti binomiali.}{4}{section*.22}%
\contentsline {paragraph}{Permutazioni.}{4}{section*.23}%
\contentsline {section}{\numberline {1.10}Entropia}{5}{section.1.10}%
\contentsline {subsection}{\numberline {1.10.1}Definizione}{5}{subsection.1.10.1}%
\contentsline {paragraph}{Proprietà essenziali.}{5}{section*.24}%
\contentsline {paragraph}{Stima empirica.}{5}{section*.25}%
\contentsline {subsection}{\numberline {1.10.2}In parole più semplici}{5}{subsection.1.10.2}%
\contentsline {paragraph}{Esempio (moneta).}{5}{section*.26}%
\contentsline {chapter}{\numberline {2}Introduzione al Data Mining}{7}{chapter.2}%
\contentsline {section}{\numberline {2.1}Definizione e finalità}{7}{section.2.1}%
\contentsline {section}{\numberline {2.2}Caratteristiche dei pattern}{7}{section.2.2}%
\contentsline {section}{\numberline {2.3}Metodi di data mining}{7}{section.2.3}%
\contentsline {section}{\numberline {2.4}Perché fare data mining}{8}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Big Data}{8}{subsection.2.4.1}%
\contentsline {subsection}{\numberline {2.4.2}Dai dati alla conoscenza e alle comunità coinvolte}{8}{subsection.2.4.2}%
\contentsline {section}{\numberline {2.5}Limiti e insidie del data mining}{8}{section.2.5}%
\contentsline {subsection}{\numberline {2.5.1}Caso di studio: Total Information Awareness (TIA)}{8}{subsection.2.5.1}%
\contentsline {subsection}{\numberline {2.5.2}Esempio: co-presenza in hotel come criterio di sospetto}{9}{subsection.2.5.2}%
\contentsline {paragraph}{Dati di partenza.}{9}{section*.27}%
\contentsline {paragraph}{Ipotesi nulla (random).}{9}{section*.28}%
\contentsline {paragraph}{Calcoli numerici.}{9}{section*.29}%
\contentsline {paragraph}{Considerazioni.}{9}{section*.30}%
\contentsline {section}{\numberline {2.6}Principio di Bonferroni e test multipli}{10}{section.2.6}%
\contentsline {paragraph}{Interpretazione operativa.}{10}{section*.31}%
\contentsline {paragraph}{Quando applicarlo.}{10}{section*.32}%
\contentsline {chapter}{\numberline {3}Preprocessing}{11}{chapter.3}%
\contentsline {section}{\numberline {3.1}Estrazione di feature}{11}{section.3.1}%
\contentsline {subsection}{\numberline {3.1.1}Tecniche di estrazione di feature}{12}{subsection.3.1.1}%
\contentsline {section}{\numberline {3.2}Portabilità dei dati}{12}{section.3.2}%
\contentsline {subsection}{\numberline {3.2.1}Da dati numerici a categorici}{12}{subsection.3.2.1}%
\contentsline {paragraph}{Equi-width ranges.}{12}{section*.33}%
\contentsline {paragraph}{Equi-log ranges.}{12}{section*.34}%
\contentsline {paragraph}{Equi-depth ranges.}{12}{section*.35}%
\contentsline {subsection}{\numberline {3.2.2}Da dati categorici a numerici}{13}{subsection.3.2.2}%
\contentsline {paragraph}{One-hot encoding.}{13}{section*.36}%
\contentsline {subsection}{\numberline {3.2.3}Da testo a dati numerici}{13}{subsection.3.2.3}%
\contentsline {section}{\numberline {3.3}Cleaning dei dati}{13}{section.3.3}%
\contentsline {subsection}{\numberline {3.3.1}Gestione dei valori mancanti}{13}{subsection.3.3.1}%
\contentsline {subsection}{\numberline {3.3.2}Gestione dei valori errati}{14}{subsection.3.3.2}%
\contentsline {paragraph}{Quantili.}{14}{section*.37}%
\contentsline {subsection}{\numberline {3.3.3}Scala dei dati}{14}{subsection.3.3.3}%
\contentsline {paragraph}{Standardizzazione.}{15}{section*.38}%
\contentsline {paragraph}{Min-Max scaling.}{15}{section*.39}%
\contentsline {section}{\numberline {3.4}Riduzione dei dati}{15}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Sampling dei dati}{15}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Selezione di feature}{16}{subsection.3.4.2}%
\contentsline {subsection}{\numberline {3.4.3}Riduzione della dimensionalità}{16}{subsection.3.4.3}%
\contentsline {subsection}{\numberline {3.4.4}PCA: Principal Component Analysis}{16}{subsection.3.4.4}%
\contentsline {subsection}{\numberline {3.4.5}SVD: Singular Value Decomposition}{18}{subsection.3.4.5}%
\contentsline {paragraph}{Interpretazione geometrica.}{18}{section*.40}%
\contentsline {paragraph}{Varianti ridotte della SVD.}{18}{section*.41}%
\contentsline {paragraph}{SVD vs PCA.}{19}{section*.42}%
\contentsline {subsection}{\numberline {3.4.6}LSA: Latent Semantic Analysis}{20}{subsection.3.4.6}%
\contentsline {subsection}{\numberline {3.4.7}Riduzione di dimensionalità con trasformazione dei dati}{20}{subsection.3.4.7}%
\contentsline {paragraph}{Esempio: serie temporali.}{20}{section*.43}%
\contentsline {chapter}{\numberline {4}Insiemi Frequenti e Regole d'Associazione}{21}{chapter.4}%
\contentsline {section}{\numberline {4.1}Market-basket model e definizioni}{21}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Supporto}{21}{subsection.4.1.1}%
\contentsline {paragraph}{Soglia di supporto: trade-off.}{21}{section*.44}%
\contentsline {section}{\numberline {4.2}Regole d'associazione}{21}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Qualità di una regola}{22}{subsection.4.2.1}%
\contentsline {paragraph}{Confidenza.}{22}{section*.45}%
\contentsline {paragraph}{Coverage.}{22}{section*.46}%
\contentsline {paragraph}{Interesse.}{22}{section*.47}%
\contentsline {paragraph}{Lift.}{22}{section*.48}%
\contentsline {paragraph}{Nota.}{22}{section*.49}%
\contentsline {paragraph}{Mini-esempio (toy dataset).}{22}{section*.50}%
\contentsline {section}{\numberline {4.3}Insiemi frequenti chiusi e massimali}{22}{section.4.3}%
\contentsline {section}{\numberline {4.4}Anti-monotonia e Principio di Apriori}{23}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Principio di Apriori}{23}{subsection.4.4.1}%
\contentsline {section}{\numberline {4.5}Algoritmo Apriori}{23}{section.4.5}%
\contentsline {subsection}{\numberline {4.5.1}Esempio Apriori (minsup = 2)}{24}{subsection.4.5.1}%
\contentsline {paragraph}{$k=1\!\to \!2$: generazione $C_2$ e conteggi.}{24}{section*.51}%
\contentsline {paragraph}{$k=2\!\to \!3$: self-join e prune.}{24}{section*.52}%
\contentsline {subsection}{\numberline {4.5.2}Generazione dei candidati}{24}{subsection.4.5.2}%
\contentsline {section}{\numberline {4.6}Ottimizzazioni di Apriori}{24}{section.4.6}%
\contentsline {subsection}{\numberline {4.6.1}Hashing in bucket: PCY}{24}{subsection.4.6.1}%
\contentsline {paragraph}{Varianti multistadio e multihash.}{25}{section*.53}%
\contentsline {subsection}{\numberline {4.6.2}Partizionamento del DB: SON}{25}{subsection.4.6.2}%
\contentsline {subsection}{\numberline {4.6.3}Campionamento e frontiera negativa: Toivonen}{25}{subsection.4.6.3}%
\contentsline {section}{\numberline {4.7}Perch\'e andare oltre Apriori}{25}{section.4.7}%
\contentsline {section}{\numberline {4.8}FP-Growth: idea di base}{25}{section.4.8}%
\contentsline {subsection}{\numberline {4.8.1}Costruzione dell'FP-tree}{25}{subsection.4.8.1}%
\contentsline {subsection}{\numberline {4.8.2}Esempio di FP-Growth}{26}{subsection.4.8.2}%
\contentsline {paragraph}{Visita per pattern-growth.}{26}{section*.54}%
\contentsline {paragraph}{Espansione di un item $x$.}{26}{section*.55}%
\contentsline {paragraph}{Esempio 1: item $p$.}{27}{section*.56}%
\contentsline {paragraph}{Esempio 2: item $m$.}{27}{section*.57}%
\contentsline {paragraph}{Esempio 3: item $b$.}{27}{section*.58}%
\contentsline {section}{\numberline {4.9}Confronto: FP-Growth vs Apriori}{27}{section.4.9}%
\contentsline {chapter}{\numberline {5}Clustering}{29}{chapter.5}%
\contentsline {section}{\numberline {5.1}Concetti generali}{29}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Spazi metrici e funzioni distanza}{29}{subsection.5.1.1}%
\contentsline {paragraph}{Distanze in spazi euclidei.}{29}{section*.59}%
\contentsline {paragraph}{Spazi non euclidei.}{30}{section*.60}%
\contentsline {subsection}{\numberline {5.1.2}Tassonomia degli algoritmi}{30}{subsection.5.1.2}%
\contentsline {paragraph}{Bontà di un algoritmo.}{30}{section*.61}%
\contentsline {subsection}{\numberline {5.1.3}Alta dimensionalità: equidistanza e ortogonalità}{30}{subsection.5.1.3}%
\contentsline {paragraph}{Equidistanza dei punti.}{30}{section*.62}%
\contentsline {paragraph}{Conseguenze pratiche.}{31}{section*.63}%
\contentsline {section}{\numberline {5.2}Clustering gerarchico}{31}{section.5.2}%
\contentsline {paragraph}{Schema agglomerativo.}{31}{section*.64}%
\contentsline {subsection}{\numberline {5.2.1}Distanza tra cluster (\emph {linkage})}{31}{subsection.5.2.1}%
\contentsline {subsection}{\numberline {5.2.2}Dendrogramma e criteri di stop}{31}{subsection.5.2.2}%
\contentsline {subsection}{\numberline {5.2.3}Altri criteri di combinazione}{31}{subsection.5.2.3}%
\contentsline {subsection}{\numberline {5.2.4}Versioni divisive}{32}{subsection.5.2.4}%
\contentsline {subsection}{\numberline {5.2.5}Complessità e ottimizzazioni}{32}{subsection.5.2.5}%
\contentsline {paragraph}{Analisi \emph {naive}.}{32}{section*.65}%
\contentsline {paragraph}{Ottimizzazione con \emph {coda di priorità}.}{32}{section*.66}%
\contentsline {section}{\numberline {5.3}Clustering partizionale: k-means}{33}{section.5.3}%
\contentsline {subsection}{\numberline {5.3.1}Algoritmo base}{33}{subsection.5.3.1}%
\contentsline {subsection}{\numberline {5.3.2}Inizializzazione}{33}{subsection.5.3.2}%
\contentsline {subsection}{\numberline {5.3.3}Funzione obiettivo e arresto}{33}{subsection.5.3.3}%
\contentsline {subsection}{\numberline {5.3.4}Scelta del numero di cluster $k$}{34}{subsection.5.3.4}%
\contentsline {paragraph}{Funzione obiettivo.}{34}{section*.67}%
\contentsline {paragraph}{Metodo \emph {elbow}.}{34}{section*.68}%
\contentsline {paragraph}{Metodo \emph {silhouette}.}{35}{section*.69}%
\contentsline {subsection}{\numberline {5.3.5}Complessità computazionale}{35}{subsection.5.3.5}%
\contentsline {section}{\numberline {5.4}Clustering per densità}{35}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}DBSCAN}{35}{subsection.5.4.1}%
\contentsline {paragraph}{Definizioni.}{35}{section*.70}%
\contentsline {paragraph}{Algoritmo.}{36}{section*.71}%
\contentsline {paragraph}{Scelta dei parametri.}{36}{section*.72}%
\contentsline {paragraph}{Complessità.}{36}{section*.73}%
\contentsline {paragraph}{Pro e contro.}{36}{section*.74}%
\contentsline {subsection}{\numberline {5.4.2}OPTICS}{36}{subsection.5.4.2}%
\contentsline {paragraph}{Core–distance e reachability (OPTICS).}{37}{section*.75}%
\contentsline {paragraph}{Risultato: ordering e \emph {reachability plot}.}{37}{section*.76}%
\contentsline {paragraph}{Estrazione dei cluster.}{37}{section*.77}%
\contentsline {paragraph}{Costo.}{38}{section*.78}%
\contentsline {subsection}{\numberline {5.4.3}HDBSCAN}{39}{subsection.5.4.3}%
\contentsline {paragraph}{Idea.}{39}{section*.79}%
\contentsline {paragraph}{Core distance di X.}{39}{section*.80}%
\contentsline {paragraph}{Distanza di \emph {mutual reachability}.}{39}{section*.81}%
\contentsline {paragraph}{Mutual Reachability graph $G_{MinPts}$.}{39}{section*.82}%
\contentsline {paragraph}{Condensed tree.}{40}{section*.85}%
\contentsline {paragraph}{Stabilità (persistenza).}{40}{section*.86}%
\contentsline {paragraph}{Estrazione dei cluster significativi (dal \emph {condensed tree}).}{40}{section*.87}%
\contentsline {paragraph}{Costo.}{41}{section*.88}%
\contentsline {chapter}{\numberline {6}Classificazione}{43}{chapter.6}%
\contentsline {section}{\numberline {6.1}Introduzione}{43}{section.6.1}%
\contentsline {paragraph}{Predizione (regressione).}{43}{section*.89}%
\contentsline {subsection}{\numberline {6.1.1}Schema generale di un classificatore}{43}{subsection.6.1.1}%
\contentsline {paragraph}{Overfitting.}{43}{section*.90}%
\contentsline {subsection}{\numberline {6.1.2}Requisiti desiderabili}{43}{subsection.6.1.2}%
\contentsline {section}{\numberline {6.2}Alberi decisionali}{44}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Classificazione tramite albero}{44}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Costruzione top–down}{44}{subsection.6.2.2}%
\contentsline {paragraph}{Pruning.}{45}{section*.91}%
\contentsline {subsection}{\numberline {6.2.3}Splitting degli attributi}{45}{subsection.6.2.3}%
\contentsline {subsection}{\numberline {6.2.4}Scelta dell’attributo e strategia greedy}{45}{subsection.6.2.4}%
\contentsline {section}{\numberline {6.3}Misure di goodness}{45}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Information Gain (ID3)}{45}{subsection.6.3.1}%
\contentsline {paragraph}{Idea.}{45}{section*.92}%
\contentsline {paragraph}{Limite noto.}{46}{section*.94}%
\contentsline {subsection}{\numberline {6.3.2}Gain Ratio (C4.5)}{46}{subsection.6.3.2}%
\contentsline {paragraph}{Selezione in C4.5.}{47}{section*.95}%
\contentsline {paragraph}{Nota pratica (attributi continui).}{47}{section*.96}%
\contentsline {subsection}{\numberline {6.3.3}Gini Index (CART)}{47}{subsection.6.3.3}%
\contentsline {subsection}{\numberline {6.3.4}Pruning degli alberi}{47}{subsection.6.3.4}%
\contentsline {paragraph}{Che cosa misurano.}{48}{section*.98}%
\contentsline {paragraph}{Decisione di pruning.}{48}{section*.99}%
\contentsline {paragraph}{Errore prima e dopo lo split.}{49}{section*.101}%
\contentsline {paragraph}{Indice di costo–complessità per lo split.}{49}{section*.102}%
\contentsline {paragraph}{Pro/contro degli alberi decisionali.}{49}{section*.103}%
\contentsline {section}{\numberline {6.4}Classificatori generativi}{49}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Teorema di Bayes e regola di decisione}{50}{subsection.6.4.1}%
\contentsline {subsection}{\numberline {6.4.2}Naive Bayes}{50}{subsection.6.4.2}%
\contentsline {paragraph}{Idea.}{50}{section*.104}%
\contentsline {paragraph}{Regola di decisione (MAP, in scala logaritmica).}{50}{section*.105}%
\contentsline {paragraph}{Stima essenziale delle probabilità.}{50}{section*.106}%
\contentsline {paragraph}{Vantaggi e svantaggi.}{50}{section*.107}%
\contentsline {subsection}{\numberline {6.4.3}Reti Bayesiane}{51}{subsection.6.4.3}%
\contentsline {paragraph}{Uso per la classificazione.}{51}{section*.108}%
\contentsline {section}{\numberline {6.5}Classificatori discriminativi}{51}{section.6.5}%
\contentsline {subsection}{\numberline {6.5.1}Classificazione lineare e non lineare}{52}{subsection.6.5.1}%
\contentsline {subsection}{\numberline {6.5.2}Perceptron}{52}{subsection.6.5.2}%
\contentsline {paragraph}{Definizione.}{52}{section*.109}%
\contentsline {paragraph}{Regola di aggiornamento.}{52}{section*.110}%
\contentsline {paragraph}{Proprietà.}{52}{section*.111}%
\contentsline {paragraph}{Algoritmo.}{52}{section*.112}%
\contentsline {paragraph}{One–Vs–One (OVO).}{53}{section*.113}%
\contentsline {paragraph}{One–Vs–All (OVA).}{53}{section*.114}%
\contentsline {subsection}{\numberline {6.5.3}Support Vector Machines (SVM)}{54}{subsection.6.5.3}%
\contentsline {paragraph}{Formulazione del problema.}{54}{section*.115}%
\contentsline {paragraph}{SVM Soft margin.}{56}{section*.116}%
\contentsline {paragraph}{Kernel Trick.}{57}{section*.117}%
\contentsline {paragraph}{SVM Multi-classe.}{58}{section*.118}%
\contentsline {section}{\numberline {6.6}Apprendimento Lazy}{58}{section.6.6}%
\contentsline {subsection}{\numberline {6.6.1}K-Nearest Neighbor}{58}{subsection.6.6.1}%
\contentsline {paragraph}{Algoritmo.}{59}{section*.119}%
\contentsline {paragraph}{Varianti.}{59}{section*.120}%
\contentsline {section}{\numberline {6.7}Ensemble Learning}{59}{section.6.7}%
\contentsline {subsection}{\numberline {6.7.1}Bagging}{59}{subsection.6.7.1}%
\contentsline {paragraph}{Algoritmo.}{59}{section*.121}%
\contentsline {paragraph}{Random Forest.}{59}{section*.122}%
\contentsline {subsection}{\numberline {6.7.2}Boosting}{60}{subsection.6.7.2}%
\contentsline {paragraph}{Algoritmo.}{60}{section*.123}%
\contentsline {subsection}{\numberline {6.7.3}Adaboost}{61}{subsection.6.7.3}%
\contentsline {paragraph}{Gini Index Pesato.}{61}{section*.124}%
\contentsline {paragraph}{Peso dello stump.}{62}{section*.125}%
\contentsline {paragraph}{Aggiornamento dei pesi.}{62}{section*.126}%
\contentsline {section}{\numberline {6.8}Validazione di un classificatore}{63}{section.6.8}%
\contentsline {subsection}{\numberline {6.8.1}Matrice di confusione}{63}{subsection.6.8.1}%
\contentsline {paragraph}{Misure di accuratezza con due classi.}{63}{section*.128}%
\contentsline {paragraph}{Misure di accuratezza (due classi).}{63}{section*.129}%
\contentsline {subsection}{\numberline {6.8.2}Soglia discriminativa in un classificatore binario}{64}{subsection.6.8.2}%
\contentsline {subsection}{\numberline {6.8.3}Curva ROC}{64}{subsection.6.8.3}%
\contentsline {subsection}{\numberline {6.8.4}Curva di Precision-Recall}{64}{subsection.6.8.4}%
\contentsline {subsection}{\numberline {6.8.5}Validazione di un classificatore}{65}{subsection.6.8.5}%
\contentsline {chapter}{\numberline {7}Regressione}{67}{chapter.7}%
\contentsline {chapter}{\numberline {8}Grafi}{69}{chapter.8}%
\contentsline {section}{\numberline {8.1}Definizione formale}{69}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}Network science}{70}{subsection.8.1.1}%
\contentsline {section}{\numberline {8.2}Grafi diretti e indiretti}{70}{section.8.2}%
\contentsline {paragraph}{Come capire che tipologia usare.}{70}{section*.130}%
\contentsline {section}{\numberline {8.3}Grafi pesati e grafi etichettati}{71}{section.8.3}%
\contentsline {section}{\numberline {8.4}Gradi dei vertici}{71}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Distribuzione dei gradi}{72}{subsection.8.4.1}%
\contentsline {section}{\numberline {8.5}Grafi bipartiti}{72}{section.8.5}%
\contentsline {paragraph}{Generalizzazione.}{73}{section*.131}%
\contentsline {section}{\numberline {8.6}Grafo completo vs Grafo regolare}{73}{section.8.6}%
\contentsline {section}{\numberline {8.7}Cammini tra due nodi}{73}{section.8.7}%
\contentsline {subsection}{\numberline {8.7.1}Cammino minimo}{73}{subsection.8.7.1}%
\contentsline {subsection}{\numberline {8.7.2}Diametro}{74}{subsection.8.7.2}%
\contentsline {subsection}{\numberline {8.7.3}Ciclo}{74}{subsection.8.7.3}%
\contentsline {paragraph}{Cappio.}{74}{section*.132}%
\contentsline {section}{\numberline {8.8}Connettività}{74}{section.8.8}%
\contentsline {subsection}{\numberline {8.8.1}Connettività forte e debole}{75}{subsection.8.8.1}%
\contentsline {section}{\numberline {8.9}Coefficiente di Clustering}{75}{section.8.9}%
\contentsline {paragraph}{Clustering medio.}{76}{section*.133}%
\contentsline {paragraph}{Coefficiente di clustering globale.}{76}{section*.134}%
\contentsline {section}{\numberline {8.10}Misure di centralità}{76}{section.8.10}%
\contentsline {subsection}{\numberline {8.10.1}Centralità di grado}{76}{subsection.8.10.1}%
\contentsline {subsection}{\numberline {8.10.2}Centralità di vicinanza}{76}{subsection.8.10.2}%
\contentsline {paragraph}{Esempio (nodo \(3\)).}{77}{section*.135}%
\contentsline {subsection}{\numberline {8.10.3}Centralità di prossimità}{78}{subsection.8.10.3}%
\contentsline {subsection}{\numberline {8.10.4}Centralità di PageRank}{78}{subsection.8.10.4}%
\contentsline {paragraph}{Esempio.}{79}{section*.136}%
\contentsline {chapter}{\numberline {9}Subgraph Matching}{81}{chapter.9}%
\contentsline {section}{\numberline {9.1}Isomorfismo di Grafi}{81}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}Automorfismo}{81}{subsection.9.1.1}%
\contentsline {section}{\numberline {9.2}Operazione di subgraph matching}{82}{section.9.2}%
\contentsline {section}{\numberline {9.3}Complessità computazionale}{83}{section.9.3}%
\contentsline {section}{\numberline {9.4}Algoritmi di subgraph matching}{83}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Soluzione Bruteforce}{83}{subsection.9.4.1}%
\contentsline {paragraph}{Esempio di backtracking.}{84}{section*.137}%
\contentsline {subsection}{\numberline {9.4.2}Algoritmo di Ullmann}{84}{subsection.9.4.2}%
\contentsline {paragraph}{Esempio della figura \ref {fig:ullmann_algorithm_example}.}{85}{section*.138}%
\contentsline {subsection}{\numberline {9.4.3}Algoritmo VF}{85}{subsection.9.4.3}%
\contentsline {paragraph}{Algoritmo.}{86}{section*.139}%
\contentsline {chapter}{\numberline {10}Elementi di Reti Neurali}{87}{chapter.10}%
