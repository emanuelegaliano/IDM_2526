\babel@toc {italian}{}\relax 
\babel@toc {italian}{}\relax 
\contentsline {part}{I\hspace {1em}Concetti Preliminari}{1}{part.1}%
\contentsline {chapter}{\numberline {1}Prerequisiti Matematici Essenziali [WIP]}{3}{chapter.1}%
\contentsline {chapter}{\numberline {2}Grafi}{5}{chapter.2}%
\contentsline {section}{\numberline {2.1}Definizione formale}{5}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}Network science}{6}{subsection.2.1.1}%
\contentsline {section}{\numberline {2.2}Grafi diretti e indiretti}{6}{section.2.2}%
\contentsline {paragraph}{Come capire che tipologia usare.}{6}{section*.2}%
\contentsline {section}{\numberline {2.3}Grafi pesati e grafi etichettati}{7}{section.2.3}%
\contentsline {section}{\numberline {2.4}Gradi dei vertici}{7}{section.2.4}%
\contentsline {subsection}{\numberline {2.4.1}Distribuzione dei gradi}{8}{subsection.2.4.1}%
\contentsline {section}{\numberline {2.5}Grafi bipartiti}{8}{section.2.5}%
\contentsline {paragraph}{Generalizzazione.}{9}{section*.3}%
\contentsline {section}{\numberline {2.6}Grafo completo vs Grafo regolare}{9}{section.2.6}%
\contentsline {section}{\numberline {2.7}Cammini tra due nodi}{9}{section.2.7}%
\contentsline {subsection}{\numberline {2.7.1}Cammino minimo}{9}{subsection.2.7.1}%
\contentsline {subsection}{\numberline {2.7.2}Diametro}{10}{subsection.2.7.2}%
\contentsline {subsection}{\numberline {2.7.3}Ciclo}{10}{subsection.2.7.3}%
\contentsline {paragraph}{Cappio.}{10}{section*.4}%
\contentsline {section}{\numberline {2.8}Connettività}{10}{section.2.8}%
\contentsline {subsection}{\numberline {2.8.1}Connettività forte e debole}{11}{subsection.2.8.1}%
\contentsline {section}{\numberline {2.9}Coefficiente di Clustering}{11}{section.2.9}%
\contentsline {paragraph}{Clustering medio.}{12}{section*.5}%
\contentsline {paragraph}{Coefficiente di clustering globale.}{12}{section*.6}%
\contentsline {section}{\numberline {2.10}Misure di centralità}{12}{section.2.10}%
\contentsline {subsection}{\numberline {2.10.1}Centralità di grado}{12}{subsection.2.10.1}%
\contentsline {subsection}{\numberline {2.10.2}Centralità di vicinanza}{12}{subsection.2.10.2}%
\contentsline {paragraph}{Esempio (nodo \(3\)).}{13}{section*.7}%
\contentsline {subsection}{\numberline {2.10.3}Centralità di prossimità}{14}{subsection.2.10.3}%
\contentsline {subsection}{\numberline {2.10.4}Centralità di PageRank}{14}{subsection.2.10.4}%
\contentsline {paragraph}{Esempio.}{15}{section*.8}%
\contentsline {part}{II\hspace {1em}Tecniche di Data Mining}{17}{part.2}%
\contentsline {chapter}{\numberline {3}Introduzione al Data Mining}{19}{chapter.3}%
\contentsline {section}{\numberline {3.1}Definizione e finalità}{19}{section.3.1}%
\contentsline {section}{\numberline {3.2}Caratteristiche dei pattern}{19}{section.3.2}%
\contentsline {section}{\numberline {3.3}Metodi di data mining}{19}{section.3.3}%
\contentsline {section}{\numberline {3.4}Perché fare data mining}{20}{section.3.4}%
\contentsline {subsection}{\numberline {3.4.1}Big Data}{20}{subsection.3.4.1}%
\contentsline {subsection}{\numberline {3.4.2}Dai dati alla conoscenza e alle comunità coinvolte}{20}{subsection.3.4.2}%
\contentsline {section}{\numberline {3.5}Limiti e insidie del data mining}{20}{section.3.5}%
\contentsline {subsection}{\numberline {3.5.1}Caso di studio: Total Information Awareness (TIA)}{20}{subsection.3.5.1}%
\contentsline {subsection}{\numberline {3.5.2}Esempio: co-presenza in hotel come criterio di sospetto}{21}{subsection.3.5.2}%
\contentsline {paragraph}{Dati di partenza.}{21}{section*.10}%
\contentsline {paragraph}{Ipotesi nulla (random).}{21}{section*.11}%
\contentsline {paragraph}{Calcoli numerici.}{21}{section*.12}%
\contentsline {paragraph}{Considerazioni.}{21}{section*.13}%
\contentsline {section}{\numberline {3.6}Principio di Bonferroni e test multipli}{22}{section.3.6}%
\contentsline {paragraph}{Interpretazione operativa.}{22}{section*.14}%
\contentsline {paragraph}{Quando applicarlo.}{22}{section*.15}%
\contentsline {chapter}{\numberline {4}Preprocessing}{23}{chapter.4}%
\contentsline {section}{\numberline {4.1}Estrazione di feature}{23}{section.4.1}%
\contentsline {subsection}{\numberline {4.1.1}Tecniche di estrazione di feature}{24}{subsection.4.1.1}%
\contentsline {section}{\numberline {4.2}Portabilità dei dati}{24}{section.4.2}%
\contentsline {subsection}{\numberline {4.2.1}Da dati numerici a categorici}{24}{subsection.4.2.1}%
\contentsline {paragraph}{Equi-width ranges.}{24}{section*.16}%
\contentsline {paragraph}{Equi-log ranges.}{24}{section*.17}%
\contentsline {paragraph}{Equi-depth ranges.}{24}{section*.18}%
\contentsline {subsection}{\numberline {4.2.2}Da dati categorici a numerici}{25}{subsection.4.2.2}%
\contentsline {paragraph}{One-hot encoding.}{25}{section*.19}%
\contentsline {subsection}{\numberline {4.2.3}Da testo a dati numerici}{25}{subsection.4.2.3}%
\contentsline {section}{\numberline {4.3}Cleaning dei dati}{25}{section.4.3}%
\contentsline {subsection}{\numberline {4.3.1}Gestione dei valori mancanti}{25}{subsection.4.3.1}%
\contentsline {subsection}{\numberline {4.3.2}Gestione dei valori errati}{26}{subsection.4.3.2}%
\contentsline {paragraph}{Quantili.}{26}{section*.20}%
\contentsline {subsection}{\numberline {4.3.3}Scala dei dati}{26}{subsection.4.3.3}%
\contentsline {paragraph}{Standardizzazione.}{27}{section*.21}%
\contentsline {paragraph}{Min-Max scaling.}{27}{section*.22}%
\contentsline {section}{\numberline {4.4}Riduzione dei dati}{27}{section.4.4}%
\contentsline {subsection}{\numberline {4.4.1}Sampling dei dati}{27}{subsection.4.4.1}%
\contentsline {subsection}{\numberline {4.4.2}Selezione di feature}{28}{subsection.4.4.2}%
\contentsline {subsection}{\numberline {4.4.3}Riduzione della dimensionalità}{28}{subsection.4.4.3}%
\contentsline {subsection}{\numberline {4.4.4}PCA: Principal Component Analysis}{28}{subsection.4.4.4}%
\contentsline {subsection}{\numberline {4.4.5}SVD: Singular Value Decomposition}{30}{subsection.4.4.5}%
\contentsline {paragraph}{Interpretazione geometrica.}{30}{section*.23}%
\contentsline {paragraph}{Varianti ridotte della SVD.}{30}{section*.24}%
\contentsline {paragraph}{SVD vs PCA.}{31}{section*.25}%
\contentsline {subsection}{\numberline {4.4.6}LSA: Latent Semantic Analysis}{32}{subsection.4.4.6}%
\contentsline {subsection}{\numberline {4.4.7}Riduzione di dimensionalità con trasformazione dei dati}{32}{subsection.4.4.7}%
\contentsline {paragraph}{Esempio: serie temporali.}{32}{section*.26}%
\contentsline {chapter}{\numberline {5}Insiemi Frequenti e Regole d'Associazione}{33}{chapter.5}%
\contentsline {section}{\numberline {5.1}Market-basket model e definizioni}{33}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Supporto}{33}{subsection.5.1.1}%
\contentsline {paragraph}{Soglia di supporto: trade-off.}{33}{section*.27}%
\contentsline {section}{\numberline {5.2}Regole d'associazione}{33}{section.5.2}%
\contentsline {subsection}{\numberline {5.2.1}Qualità di una regola}{34}{subsection.5.2.1}%
\contentsline {paragraph}{Confidenza.}{34}{section*.28}%
\contentsline {paragraph}{Coverage.}{34}{section*.29}%
\contentsline {paragraph}{Interesse.}{34}{section*.30}%
\contentsline {paragraph}{Lift.}{34}{section*.31}%
\contentsline {paragraph}{Nota.}{34}{section*.32}%
\contentsline {paragraph}{Mini-esempio (toy dataset).}{34}{section*.33}%
\contentsline {section}{\numberline {5.3}Insiemi frequenti chiusi e massimali}{34}{section.5.3}%
\contentsline {section}{\numberline {5.4}Anti-monotonia e Principio di Apriori}{35}{section.5.4}%
\contentsline {subsection}{\numberline {5.4.1}Principio di Apriori}{35}{subsection.5.4.1}%
\contentsline {section}{\numberline {5.5}Algoritmo Apriori}{35}{section.5.5}%
\contentsline {subsection}{\numberline {5.5.1}Esempio Apriori (minsup = 2)}{36}{subsection.5.5.1}%
\contentsline {paragraph}{$k=1\!\to \!2$: generazione $C_2$ e conteggi.}{36}{section*.34}%
\contentsline {paragraph}{$k=2\!\to \!3$: self-join e prune.}{36}{section*.35}%
\contentsline {subsection}{\numberline {5.5.2}Generazione dei candidati}{36}{subsection.5.5.2}%
\contentsline {section}{\numberline {5.6}Ottimizzazioni di Apriori}{36}{section.5.6}%
\contentsline {subsection}{\numberline {5.6.1}Hashing in bucket: PCY}{36}{subsection.5.6.1}%
\contentsline {paragraph}{Varianti multistadio e multihash.}{37}{section*.36}%
\contentsline {subsection}{\numberline {5.6.2}Partizionamento del DB: SON}{37}{subsection.5.6.2}%
\contentsline {subsection}{\numberline {5.6.3}Campionamento e frontiera negativa: Toivonen}{37}{subsection.5.6.3}%
\contentsline {section}{\numberline {5.7}Perch\'e andare oltre Apriori}{37}{section.5.7}%
\contentsline {section}{\numberline {5.8}FP-Growth: idea di base}{37}{section.5.8}%
\contentsline {subsection}{\numberline {5.8.1}Costruzione dell'FP-tree}{37}{subsection.5.8.1}%
\contentsline {subsection}{\numberline {5.8.2}Esempio di FP-Growth}{38}{subsection.5.8.2}%
\contentsline {paragraph}{Visita per pattern-growth.}{38}{section*.37}%
\contentsline {paragraph}{Espansione di un item $x$.}{38}{section*.38}%
\contentsline {paragraph}{Esempio 1: item $p$.}{39}{section*.39}%
\contentsline {paragraph}{Esempio 2: item $m$.}{39}{section*.40}%
\contentsline {paragraph}{Esempio 3: item $b$.}{39}{section*.41}%
\contentsline {section}{\numberline {5.9}Confronto: FP-Growth vs Apriori}{39}{section.5.9}%
\contentsline {chapter}{\numberline {6}Clustering}{41}{chapter.6}%
\contentsline {section}{\numberline {6.1}Concetti generali}{41}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Spazi metrici e funzioni distanza}{41}{subsection.6.1.1}%
\contentsline {paragraph}{Distanze in spazi euclidei.}{41}{section*.42}%
\contentsline {paragraph}{Spazi non euclidei.}{42}{section*.43}%
\contentsline {subsection}{\numberline {6.1.2}Tassonomia degli algoritmi}{42}{subsection.6.1.2}%
\contentsline {paragraph}{Bontà di un algoritmo.}{42}{section*.44}%
\contentsline {subsection}{\numberline {6.1.3}Alta dimensionalità: equidistanza e ortogonalità}{42}{subsection.6.1.3}%
\contentsline {paragraph}{Equidistanza dei punti.}{42}{section*.45}%
\contentsline {paragraph}{Conseguenze pratiche.}{43}{section*.46}%
\contentsline {section}{\numberline {6.2}Clustering gerarchico}{43}{section.6.2}%
\contentsline {paragraph}{Schema agglomerativo.}{43}{section*.47}%
\contentsline {subsection}{\numberline {6.2.1}Distanza tra cluster (\emph {linkage})}{43}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Dendrogramma e criteri di stop}{43}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Altri criteri di combinazione}{43}{subsection.6.2.3}%
\contentsline {subsection}{\numberline {6.2.4}Versioni divisive}{44}{subsection.6.2.4}%
\contentsline {subsection}{\numberline {6.2.5}Complessità e ottimizzazioni}{44}{subsection.6.2.5}%
\contentsline {paragraph}{Analisi \emph {naive}.}{44}{section*.48}%
\contentsline {paragraph}{Ottimizzazione con \emph {coda di priorità}.}{44}{section*.49}%
\contentsline {section}{\numberline {6.3}Clustering partizionale: k-means}{45}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Algoritmo base}{45}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Inizializzazione}{45}{subsection.6.3.2}%
\contentsline {subsection}{\numberline {6.3.3}Funzione obiettivo e arresto}{45}{subsection.6.3.3}%
\contentsline {subsection}{\numberline {6.3.4}Scelta del numero di cluster $\mathbf {k}$}{46}{subsection.6.3.4}%
\contentsline {paragraph}{Funzione obiettivo.}{46}{section*.50}%
\contentsline {paragraph}{Metodo \emph {elbow}.}{46}{section*.51}%
\contentsline {paragraph}{Metodo \emph {silhouette}.}{47}{section*.52}%
\contentsline {subsection}{\numberline {6.3.5}Complessità computazionale}{47}{subsection.6.3.5}%
\contentsline {section}{\numberline {6.4}Clustering per densità}{47}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}DBSCAN}{47}{subsection.6.4.1}%
\contentsline {paragraph}{Definizioni.}{47}{section*.53}%
\contentsline {paragraph}{Algoritmo.}{48}{section*.54}%
\contentsline {paragraph}{Scelta dei parametri.}{48}{section*.55}%
\contentsline {paragraph}{Complessità.}{48}{section*.56}%
\contentsline {paragraph}{Pro e contro.}{48}{section*.57}%
\contentsline {subsection}{\numberline {6.4.2}OPTICS}{48}{subsection.6.4.2}%
\contentsline {paragraph}{Core–distance e reachability (OPTICS).}{49}{section*.58}%
\contentsline {paragraph}{Risultato: ordering e \emph {reachability plot}.}{49}{section*.59}%
\contentsline {paragraph}{Estrazione dei cluster.}{49}{section*.60}%
\contentsline {paragraph}{Costo.}{50}{section*.61}%
\contentsline {subsection}{\numberline {6.4.3}HDBSCAN}{51}{subsection.6.4.3}%
\contentsline {paragraph}{Idea.}{51}{section*.62}%
\contentsline {paragraph}{Core distance di X.}{51}{section*.63}%
\contentsline {paragraph}{Distanza di \emph {mutual reachability}.}{51}{section*.64}%
\contentsline {paragraph}{Mutual Reachability graph $G_{MinPts}$.}{51}{section*.65}%
\contentsline {paragraph}{Condensed tree.}{52}{section*.68}%
\contentsline {paragraph}{Stabilità (persistenza).}{52}{section*.69}%
\contentsline {paragraph}{Estrazione dei cluster significativi (dal \emph {condensed tree}).}{52}{section*.70}%
\contentsline {paragraph}{Costo.}{53}{section*.71}%
\contentsline {chapter}{\numberline {7}Clustering}{55}{chapter.7}%
\contentsline {section}{\numberline {7.1}Spazi metrici e distanze}{55}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Spazio euclideo}{55}{subsection.7.1.1}%
\contentsline {paragraph}{Centroide.}{56}{section*.72}%
\contentsline {subsection}{\numberline {7.1.2}Spazi non euclidei}{56}{subsection.7.1.2}%
\contentsline {section}{\numberline {7.2}Algoritmi di clustering}{57}{section.7.2}%
\contentsline {subsection}{\numberline {7.2.1}Tipi di clustering}{57}{subsection.7.2.1}%
\contentsline {subsection}{\numberline {7.2.2}Bontà di un algoritmo}{57}{subsection.7.2.2}%
\contentsline {subsection}{\numberline {7.2.3}Curse of dimensionality}{58}{subsection.7.2.3}%
\contentsline {subsection}{\numberline {7.2.4}Ortogonalità dei vettori}{58}{subsection.7.2.4}%
\contentsline {section}{\numberline {7.3}Clustering Gerarchico}{59}{section.7.3}%
\contentsline {subsection}{\numberline {7.3.1}Distanze tra cluster}{59}{subsection.7.3.1}%
\contentsline {subsection}{\numberline {7.3.2}Dendrogramma}{59}{subsection.7.3.2}%
\contentsline {subsection}{\numberline {7.3.3}Clustering divisivo}{61}{subsection.7.3.3}%
\contentsline {subsection}{\numberline {7.3.4}Complessità computazionale}{61}{subsection.7.3.4}%
\contentsline {section}{\numberline {7.4}Clustering partizionale: K-means}{61}{section.7.4}%
\contentsline {subsection}{\numberline {7.4.1}Scelta greedy dei centroidi iniziali}{62}{subsection.7.4.1}%
\contentsline {subsection}{\numberline {7.4.2}Funzione obiettivo}{62}{subsection.7.4.2}%
\contentsline {subsection}{\numberline {7.4.3}Scelta del numero di cluster}{62}{subsection.7.4.3}%
\contentsline {paragraph}{Metodo elbow.}{62}{section*.73}%
\contentsline {paragraph}{Metodo silhouette.}{63}{section*.74}%
\contentsline {subsection}{\numberline {7.4.4}Complessità computazionale}{64}{subsection.7.4.4}%
\contentsline {subsection}{\numberline {7.4.5}K-means su Big data}{65}{subsection.7.4.5}%
\contentsline {chapter}{\numberline {8}Classificazione}{67}{chapter.8}%
\contentsline {section}{\numberline {8.1}Introduzione}{67}{section.8.1}%
\contentsline {paragraph}{Predizione (regressione).}{67}{section*.75}%
\contentsline {subsection}{\numberline {8.1.1}Schema generale di un classificatore}{67}{subsection.8.1.1}%
\contentsline {paragraph}{Overfitting.}{67}{section*.76}%
\contentsline {subsection}{\numberline {8.1.2}Requisiti desiderabili}{67}{subsection.8.1.2}%
\contentsline {section}{\numberline {8.2}Alberi decisionali}{68}{section.8.2}%
\contentsline {subsection}{\numberline {8.2.1}Classificazione tramite albero}{68}{subsection.8.2.1}%
\contentsline {subsection}{\numberline {8.2.2}Costruzione top–down}{68}{subsection.8.2.2}%
\contentsline {paragraph}{Pruning.}{69}{section*.77}%
\contentsline {subsection}{\numberline {8.2.3}Splitting degli attributi}{69}{subsection.8.2.3}%
\contentsline {subsection}{\numberline {8.2.4}Scelta dell’attributo e strategia greedy}{69}{subsection.8.2.4}%
\contentsline {section}{\numberline {8.3}Misure di goodness}{69}{section.8.3}%
\contentsline {subsection}{\numberline {8.3.1}Information Gain (ID3)}{69}{subsection.8.3.1}%
\contentsline {paragraph}{Idea.}{69}{section*.78}%
\contentsline {paragraph}{Limite noto.}{70}{section*.80}%
\contentsline {subsection}{\numberline {8.3.2}Gain Ratio (C4.5)}{70}{subsection.8.3.2}%
\contentsline {paragraph}{Selezione in C4.5.}{71}{section*.81}%
\contentsline {paragraph}{Nota pratica (attributi continui).}{71}{section*.82}%
\contentsline {subsection}{\numberline {8.3.3}Gini Index (CART)}{71}{subsection.8.3.3}%
\contentsline {subsection}{\numberline {8.3.4}Pruning degli alberi}{71}{subsection.8.3.4}%
\contentsline {paragraph}{Che cosa misurano.}{72}{section*.84}%
\contentsline {paragraph}{Decisione di pruning.}{72}{section*.85}%
\contentsline {paragraph}{Errore prima e dopo lo split.}{73}{section*.87}%
\contentsline {paragraph}{Indice di costo–complessità per lo split.}{73}{section*.88}%
\contentsline {paragraph}{Pro/contro degli alberi decisionali.}{73}{section*.89}%
\contentsline {section}{\numberline {8.4}Classificatori generativi}{73}{section.8.4}%
\contentsline {subsection}{\numberline {8.4.1}Teorema di Bayes e regola di decisione}{74}{subsection.8.4.1}%
\contentsline {subsection}{\numberline {8.4.2}Naive Bayes}{74}{subsection.8.4.2}%
\contentsline {paragraph}{Idea.}{74}{section*.90}%
\contentsline {paragraph}{Regola di decisione (MAP, in scala logaritmica).}{74}{section*.91}%
\contentsline {paragraph}{Stima essenziale delle probabilità.}{74}{section*.92}%
\contentsline {paragraph}{Vantaggi e svantaggi.}{74}{section*.93}%
\contentsline {subsection}{\numberline {8.4.3}Reti Bayesiane}{75}{subsection.8.4.3}%
\contentsline {paragraph}{Uso per la classificazione.}{75}{section*.94}%
\contentsline {section}{\numberline {8.5}Classificatori discriminativi}{75}{section.8.5}%
\contentsline {subsection}{\numberline {8.5.1}Classificazione lineare e non lineare}{76}{subsection.8.5.1}%
\contentsline {subsection}{\numberline {8.5.2}Perceptron}{76}{subsection.8.5.2}%
\contentsline {paragraph}{Definizione.}{76}{section*.95}%
\contentsline {paragraph}{Regola di aggiornamento.}{76}{section*.96}%
\contentsline {paragraph}{Proprietà.}{76}{section*.97}%
\contentsline {paragraph}{Algoritmo.}{76}{section*.98}%
\contentsline {paragraph}{One–Vs–One (OVO).}{77}{section*.99}%
\contentsline {paragraph}{One–Vs–All (OVA).}{77}{section*.100}%
\contentsline {subsection}{\numberline {8.5.3}Support Vector Machines (SVM)}{78}{subsection.8.5.3}%
\contentsline {paragraph}{Formulazione del problema.}{78}{section*.101}%
\contentsline {paragraph}{SVM Soft margin.}{80}{section*.102}%
\contentsline {paragraph}{Kernel Trick.}{81}{section*.103}%
\contentsline {paragraph}{SVM Multi-classe.}{82}{section*.104}%
\contentsline {section}{\numberline {8.6}Apprendimento Lazy}{82}{section.8.6}%
\contentsline {subsection}{\numberline {8.6.1}K-Nearest Neighbor}{82}{subsection.8.6.1}%
\contentsline {paragraph}{Algoritmo.}{83}{section*.105}%
\contentsline {paragraph}{Varianti.}{83}{section*.106}%
\contentsline {section}{\numberline {8.7}Ensemble Learning}{83}{section.8.7}%
\contentsline {subsection}{\numberline {8.7.1}Bagging}{83}{subsection.8.7.1}%
\contentsline {paragraph}{Algoritmo.}{83}{section*.107}%
\contentsline {paragraph}{Random Forest.}{83}{section*.108}%
\contentsline {subsection}{\numberline {8.7.2}Boosting}{84}{subsection.8.7.2}%
\contentsline {paragraph}{Algoritmo.}{84}{section*.109}%
\contentsline {subsection}{\numberline {8.7.3}Adaboost}{85}{subsection.8.7.3}%
\contentsline {paragraph}{Gini Index Pesato.}{85}{section*.110}%
\contentsline {paragraph}{Peso dello stump.}{86}{section*.111}%
\contentsline {paragraph}{Aggiornamento dei pesi.}{86}{section*.112}%
\contentsline {section}{\numberline {8.8}Validazione di un classificatore}{87}{section.8.8}%
\contentsline {subsection}{\numberline {8.8.1}Matrice di confusione}{87}{subsection.8.8.1}%
\contentsline {paragraph}{Misure di accuratezza con due classi.}{87}{section*.114}%
\contentsline {paragraph}{Misure di accuratezza (due classi).}{87}{section*.115}%
\contentsline {subsection}{\numberline {8.8.2}Soglia discriminativa in un classificatore binario}{88}{subsection.8.8.2}%
\contentsline {subsection}{\numberline {8.8.3}Curva ROC}{88}{subsection.8.8.3}%
\contentsline {subsection}{\numberline {8.8.4}Curva di Precision-Recall}{88}{subsection.8.8.4}%
\contentsline {subsection}{\numberline {8.8.5}Validazione di un classificatore}{89}{subsection.8.8.5}%
\contentsline {chapter}{\numberline {9}Cenni di Regressione}{91}{chapter.9}%
\contentsline {section}{\numberline {9.1}Regressione lineare semplice}{91}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}Formulazione del modello}{91}{subsection.9.1.1}%
\contentsline {subsection}{\numberline {9.1.2}Stima dei parametri}{92}{subsection.9.1.2}%
\contentsline {subsection}{\numberline {9.1.3}Interpretazione geoemetrica}{92}{subsection.9.1.3}%
\contentsline {section}{\numberline {9.2}Regressione lineare multipla}{92}{section.9.2}%
\contentsline {subsection}{\numberline {9.2.1}Formulazione del modello}{92}{subsection.9.2.1}%
\contentsline {subsection}{\numberline {9.2.2}Stima dei parametri}{93}{subsection.9.2.2}%
\contentsline {subsection}{\numberline {9.2.3}Interpretazione geometrica}{93}{subsection.9.2.3}%
\contentsline {section}{\numberline {9.3}Regressione non lineare}{93}{section.9.3}%
\contentsline {section}{\numberline {9.4}Regressione logistica}{93}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Regressione logistica binaria semplice}{94}{subsection.9.4.1}%
\contentsline {paragraph}{Stima dei parametri.}{94}{section*.116}%
\contentsline {chapter}{\numberline {10}Subgraph Matching}{95}{chapter.10}%
\contentsline {section}{\numberline {10.1}Isomorfismo di Grafi}{95}{section.10.1}%
\contentsline {subsection}{\numberline {10.1.1}Automorfismo}{95}{subsection.10.1.1}%
\contentsline {section}{\numberline {10.2}Operazione di subgraph matching}{96}{section.10.2}%
\contentsline {section}{\numberline {10.3}Complessità computazionale}{97}{section.10.3}%
\contentsline {section}{\numberline {10.4}Algoritmi di subgraph matching}{97}{section.10.4}%
\contentsline {subsection}{\numberline {10.4.1}Soluzione Bruteforce}{97}{subsection.10.4.1}%
\contentsline {paragraph}{Esempio di backtracking.}{98}{section*.118}%
\contentsline {subsection}{\numberline {10.4.2}Algoritmo di Ullmann}{98}{subsection.10.4.2}%
\contentsline {paragraph}{Esempio della figura \ref {fig:ullmann_algorithm_example}.}{99}{section*.119}%
\contentsline {subsection}{\numberline {10.4.3}Algoritmo VF}{99}{subsection.10.4.3}%
\contentsline {paragraph}{Algoritmo.}{100}{section*.120}%
\contentsline {paragraph}{Regola di fattibilità per grafi indiretti.}{100}{section*.121}%
\contentsline {paragraph}{Regola di fattibilità per grafi diretti.}{100}{section*.122}%
\contentsline {paragraph}{Complessità e considerazioni}{102}{section*.123}%
\contentsline {subsection}{\numberline {10.4.4}Algoritmo VF2}{102}{subsection.10.4.4}%
\contentsline {subsection}{\numberline {10.4.5}Algoritmo RI}{103}{subsection.10.4.5}%
\contentsline {paragraph}{Ordinamento dei nodi.}{103}{section*.124}%
\contentsline {paragraph}{Passo $i=1$.}{104}{section*.126}%
\contentsline {paragraph}{Passo $i=2$.}{104}{section*.127}%
\contentsline {paragraph}{Tabella finale}{105}{section*.128}%
\contentsline {subsection}{\numberline {10.4.6}RI-DS}{105}{subsection.10.4.6}%
\contentsline {section}{\numberline {10.5}Subgraph Matching in Database di Grafi}{105}{section.10.5}%
\contentsline {subsection}{\numberline {10.5.1}Indicizzazione}{106}{subsection.10.5.1}%
\contentsline {section}{\numberline {10.6}Features dei grafi}{106}{section.10.6}%
\contentsline {paragraph}{Esempio di filtraggio tramite profili di feature.}{106}{figure.10.9}%
\contentsline {subsection}{\numberline {10.6.1}Schema di subgraph matching in database di grafi}{107}{subsection.10.6.1}%
\contentsline {subsection}{\numberline {10.6.2}Indicizzazione inversa}{108}{subsection.10.6.2}%
\contentsline {subsection}{\numberline {10.6.3}Algoritmo SING}{108}{subsection.10.6.3}%
\contentsline {paragraph}{Processamento della query.}{108}{section*.130}%
\contentsline {chapter}{\numberline {11}Subgraph Matching di Grafi Frequenti}{111}{chapter.11}%
\contentsline {section}{\numberline {11.1}Algoritmo FSG}{112}{section.11.1}%
\contentsline {subsection}{\numberline {11.1.1}Regola Apriori per sotto-grafi}{112}{subsection.11.1.1}%
\contentsline {subsection}{\numberline {11.1.2}Join tra sotto-grafi}{113}{subsection.11.1.2}%
\contentsline {paragraph}{Scenario 1: i due sottografi differiscono per un nodo.}{113}{figure.11.3}%
\contentsline {paragraph}{Scenario 2: il grafo \emph {core} ha più automorfismi.}{113}{figure.11.4}%
\contentsline {paragraph}{Scenario 3: i sottografi candidati hanno più grafi \emph {core} in comune.}{114}{figure.11.5}%
\contentsline {paragraph}{Caso generale.}{116}{section*.135}%
\contentsline {subsection}{\numberline {11.1.3}Procedura dell'algoritmo}{116}{subsection.11.1.3}%
\contentsline {subsection}{\numberline {11.1.4}Generazione dei candidati}{116}{subsection.11.1.4}%
\contentsline {subsection}{\numberline {11.1.5}Stringa di adiacenza}{117}{subsection.11.1.5}%
\contentsline {subsection}{\numberline {11.1.6}Forma canonica}{117}{subsection.11.1.6}%
\contentsline {paragraph}{Algoritmo.}{117}{section*.136}%
\contentsline {paragraph}{Esempio.}{117}{section*.137}%
\contentsline {subsection}{\numberline {11.1.7}Verifica della regola Apriori}{118}{subsection.11.1.7}%
\contentsline {section}{\numberline {11.2}Algoritmo gSpan}{119}{section.11.2}%
\contentsline {subsection}{\numberline {11.2.1}Visita DFS}{119}{subsection.11.2.1}%
\contentsline {paragraph}{Albero DFS.}{119}{section*.138}%
\contentsline {subsection}{\numberline {11.2.2}Codifica DFS}{119}{subsection.11.2.2}%
\contentsline {paragraph}{Costruzione della codifica DFS.}{121}{section*.139}%
\contentsline {paragraph}{Codice DFS minimo.}{121}{section*.140}%
\contentsline {paragraph}{DFS Code Tree.}{121}{section*.141}%
\contentsline {subsection}{\numberline {11.2.3}Generazione dei candidati}{122}{subsection.11.2.3}%
\contentsline {paragraph}{Pruning dello spazio di ricerca.}{123}{section*.142}%
\contentsline {chapter}{\numberline {12}Elementi di Reti neurali}{125}{chapter.12}%
\contentsline {section}{\numberline {12.1}Strati}{126}{section.12.1}%
\contentsline {paragraph}{Deep neural network.}{126}{section*.144}%
\contentsline {subsection}{\numberline {12.1.1}Connessioni tra layer}{127}{subsection.12.1.1}%
\contentsline {section}{\numberline {12.2}Progettare una rete neurale}{127}{section.12.2}%
\contentsline {section}{\numberline {12.3}Funzioni di attivazione}{127}{section.12.3}%
\contentsline {paragraph}{Proprietà.}{128}{section*.145}%
\contentsline {subsection}{\numberline {12.3.1}Funzione step}{128}{subsection.12.3.1}%
\contentsline {subsection}{\numberline {12.3.2}Funzione logistica}{129}{subsection.12.3.2}%
\contentsline {subsection}{\numberline {12.3.3}Tangente iperbolica}{130}{subsection.12.3.3}%
\contentsline {subsection}{\numberline {12.3.4}Funzione softmax}{130}{subsection.12.3.4}%
\contentsline {subsection}{\numberline {12.3.5}ReLU: Rectified Linear Unit}{131}{subsection.12.3.5}%
\contentsline {paragraph}{Variante ELU.}{132}{section*.146}%
\contentsline {section}{\numberline {12.4}Funzioni Loss}{132}{section.12.4}%
\contentsline {subsection}{\numberline {12.4.1}Regression Loss}{132}{subsection.12.4.1}%
\contentsline {paragraph}{MSE: Mean Squared Error.}{133}{section*.147}%
\contentsline {subsection}{\numberline {12.4.2}Classification Loss}{134}{subsection.12.4.2}%
\contentsline {paragraph}{Entropia.}{134}{section*.148}%
\contentsline {paragraph}{Entropia incrociata.}{134}{section*.149}%
\contentsline {section}{\numberline {12.5}Training di una rete neurale}{135}{section.12.5}%
\contentsline {subsection}{\numberline {12.5.1}Ottimizzazione dei pesi}{135}{subsection.12.5.1}%
\contentsline {subsection}{\numberline {12.5.2}Metodo di discesa del gradiente}{135}{subsection.12.5.2}%
\contentsline {paragraph}{Matrice Jacobiana.}{137}{section*.150}%
\contentsline {paragraph}{Stochastic Gradient Descent.}{137}{section*.151}%
\contentsline {subsection}{\numberline {12.5.3}Esempio di computazione}{137}{subsection.12.5.3}%
\contentsline {subsection}{\numberline {12.5.4}Backpropagation}{138}{subsection.12.5.4}%
\contentsline {paragraph}{Regola della catena.}{138}{section*.152}%
\contentsline {paragraph}{Esempio.}{139}{section*.153}%
\contentsline {section}{\numberline {12.6}Tecniche di Regolarizzazione}{141}{section.12.6}%
\contentsline {subsection}{\numberline {12.6.1}Regolarizzazione L1 e L2}{141}{subsection.12.6.1}%
\contentsline {subsection}{\numberline {12.6.2}Dropout}{142}{subsection.12.6.2}%
\contentsline {subsection}{\numberline {12.6.3}Early Stopping}{142}{subsection.12.6.3}%
\contentsline {subsection}{\numberline {12.6.4}Aumento del training set}{142}{subsection.12.6.4}%
\contentsline {section}{\numberline {12.7}Tipi di reti neurali}{143}{section.12.7}%
\contentsline {subsection}{\numberline {12.7.1}Feed-Forward Networks}{143}{subsection.12.7.1}%
\contentsline {subsection}{\numberline {12.7.2}Reti Neurali Convoluzionali}{143}{subsection.12.7.2}%
\contentsline {paragraph}{Fotorecettori.}{144}{section*.154}%
\contentsline {paragraph}{Convolutional Layer.}{144}{section*.155}%
\contentsline {paragraph}{Stride.}{144}{section*.156}%
\contentsline {paragraph}{Zero Padding.}{144}{section*.157}%
\contentsline {paragraph}{Pooling Layer.}{144}{section*.158}%
\contentsline {paragraph}{CNN su immagini a colori.}{145}{section*.159}%
\contentsline {subsection}{\numberline {12.7.3}Rete neurali di grafi}{145}{subsection.12.7.3}%
\contentsline {subsection}{\numberline {12.7.4}Reti Neurali Ricorrenti}{146}{subsection.12.7.4}%
\contentsline {paragraph}{Input di una RNN.}{146}{section*.160}%
\contentsline {subsection}{\numberline {12.7.5}LSTM: Long Short-Term Memory}{147}{subsection.12.7.5}%
\contentsline {paragraph}{Aggiornamento della cella di memoria.}{148}{section*.161}%
\contentsline {subsection}{\numberline {12.7.6}Autoencoder}{150}{subsection.12.7.6}%
\contentsline {paragraph}{Varianti di autoencoder.}{150}{section*.162}%
\contentsline {subsection}{\numberline {12.7.7}Variational Autoencoder}{150}{subsection.12.7.7}%
\contentsline {paragraph}{Loss function dei VAE.}{151}{section*.163}%
\contentsline {paragraph}{Applicazione di VAE.}{151}{section*.164}%
\contentsline {chapter}{\numberline {13}Introduzione a Transformer e LLM}{153}{chapter.13}%
\contentsline {part}{III\hspace {1em}Approfondimenti}{155}{part.3}%
