\chapter{Introduzione al Data Mining}\label{ch:introduzione}

\section{Definizione e finalità}\label{sec:definizione}
Il \emph{Data Mining} consiste nello scoprire \emph{pattern} (modelli e regolarità) interessanti e possibilmente inattesi all'interno di un insieme di dati. Le conoscenze estratte possono essere impiegate per supportare decisioni, formulare previsioni o fungere da base per ulteriori attività (ad es.\ profilazione di utenti).
%
\begin{itemize}
  \item \textbf{Data cleaning (pre-processing)}: individuare e rimuovere artefatti e dati fittizi o rumorosi, armonizzare formati, gestire valori mancanti.
  \item \textbf{Visualizzazione}: comunicare in modo efficace i risultati del processo di data mining.
\end{itemize}

\section{Caratteristiche dei pattern}\label{sec:caratteristiche-pattern}
I pattern da estrarre dovrebbero essere:
\begin{itemize}
  \item \textbf{Validi}: veri (con alta probabilità) anche su dati nuovi non visti.
  \item \textbf{Utili}: capaci di suggerire o guidare azioni concrete.
  \item \textbf{Inattesi}: non banali, non ovvi.
  \item \textbf{Comprensibili}: interpretabili da esseri umani.
\end{itemize}

\section{Metodi di data mining}\label{sec:metodi}
Gli algoritmi di data mining si distinguono in:
\begin{itemize}
  \item \textbf{Descrittivi}: mirano a rappresentare e \emph{descrivere} la struttura dei dati (es.\ clustering, regole di associazione, analisi di similarità).
  \item \textbf{Predittivi}: usano alcune variabili per \emph{predire} valori sconosciuti o futuri (es.\ classificazione, regressione, sistemi di raccomandazione).
\end{itemize}

\section{Perché fare data mining}\label{sec:motivazioni}
Negli ultimi anni la quantità di dati disponibili è esplosa. Le principali sorgenti includono:
\begin{itemize}
  \item \textbf{Business}: web, e-commerce, transazioni, mercati finanziari, log applicativi.
  \item \textbf{Multimedia}: video, audio, testo, immagini.
  \item \textbf{Scienza}: telerilevamento, medicina, bioinformatica.
  \item \textbf{Società}: news, e-mail, social network, forum.
\end{itemize}

\subsection{Big Data}\label{subsec:bigdata}
I dati moderni sono spesso:
\begin{itemize}
  \item \textbf{Grandi} (\emph{volume});
  \item \textbf{Ad elevata dimensionalità} (\emph{varietà} di attributi);
  \item \textbf{Complessi} (relazionali, temporali, eterogenei).
\end{itemize}
La sola disponibilità di molti dati non si traduce automaticamente in conoscenza: servono metodi e strumenti per analizzarli in modo efficace.

\subsection{Dai dati alla conoscenza e alle comunità coinvolte}\label{subsec:comunita}
L'enorme quantità di dati non diventa automaticamente conoscenza: occorre trasformarla con tecniche appropriate. Il data mining è al crocevia di più comunità scientifiche (apprendimento automatico, pattern recognition, visualizzazione, algoritmi, \ldots).

\section{Limiti e insidie del data mining}\label{sec:limiti}
Un'idea intuitiva (ma pericolosa) è: ``raccogliamo quanti più dati possibile e troveremo pattern affidabili''. In realtà, al crescere della dimensione aumenta anche la probabilità di osservare regolarità \emph{spurie}, cioè non realmente significative. Consideriamo un caso di studio.

\subsection{Caso di studio: Total Information Awareness (TIA)}\label{subsec:tia}
Dopo gli attentati dell'11 settembre 2001, il Dipartimento della Difesa degli Stati Uniti propose il programma \emph{Total Information Awareness} (TIA), volto a raccogliere in modo massivo informazioni su persone (ricevute di pagamento, spostamenti, ecc.) per prevenire attacchi terroristici. Al di là delle criticità etiche e di privacy, un rischio metodologico è la generazione di moltissimi \emph{falsi positivi}: attività apparentemente anomale ma statisticamente spiegabili.

\subsection{Esempio: co-presenza in hotel come criterio di sospetto}\label{subsec:esempio-hotel}
Vogliamo identificare potenziali coppie di malfattori assumendo che essi si riuniscano periodicamente nello stesso hotel. Sui dati osservati cerchiamo tutte le coppie di persone che, in \emph{due} giorni distinti, risultano nello \emph{stesso} hotel.
%
\paragraph{Dati di partenza.}
\begin{itemize}
  \item Numero di persone tracciate: $N = 10^9$.
  \item Orizzonte temporale: $D = 1000$ giorni.
  \item Numero di hotel: $H = 10^5$.
  \item Capacità per hotel e per giorno: $C = 100$ persone.
\end{itemize}
\paragraph{Ipotesi nulla (random).} Ogni persona, in ciascun giorno, sceglie in modo casuale e indipendente se (e dove) soggiornare; in particolare, per un dato hotel in un dato giorno la probabilità che una persona vi alloggi è
\[
  P(\text{persona in un hotel specifico in un giorno}) \;=\; \frac{C}{N} \;=\; \frac{100}{10^9} \;=\; 10^{-7}.
\]
\paragraph{Calcoli numerici.}
\begin{enumerate}
  \item \textbf{Stesso hotel in un giorno fissato.} Per due persone specifiche $p,q$, la probabilità di trovarle nello stesso hotel in un \emph{giorno specifico} è
  \[
    P_1 \;=\; H \cdot \left(\frac{C}{N}\right)^2 \;=\; 10^5 \cdot (10^{-7})^2 \;=\; 10^{-9}.
  \]
  \item \textbf{Due giorni distinti non specificati.} Le coppie di giorni distinti sono $\binom{D}{2} = \frac{D(D-1)}{2} \approx \frac{1000\cdot 999}{2} \approx 5\cdot 10^5$. Supponendo indipendenza tra i giorni, la probabilità che $p,q$ si trovino nello stesso hotel in \emph{entrambi} i due giorni è
  \[
    P_2 \;=\; \binom{D}{2}\cdot P_1^2 \;=\; \left(5\cdot 10^5\right)\cdot (10^{-9})^2 \;=\; 5\cdot 10^{-13}.
  \]
  \item \textbf{Numero atteso di coppie sospette.} Le coppie distinte di persone sono $\binom{N}{2}\approx \frac{10^9(10^9-1)}{2}\approx 5\cdot 10^{17}$. Il numero atteso di coppie candidate è dunque
  \[
    \mathbb{E}[\#\text{coppie}] \;=\; P_2 \cdot \binom{N}{2} \;\approx\; \left(5\cdot 10^{-13}\right)\cdot \left(5\cdot 10^{17}\right) \;=\; 2{,}5\cdot 10^{5}.
  \]
\end{enumerate}

\paragraph{Considerazioni.} Verificare manualmente $\sim 250{,}000$ coppie è impraticabile, specie a fronte di un numero reale di coppie colpevoli verosimilmente molto più basso. L'esempio mostra come, su dati enormi, criteri apparentemente sensati possano generare moltissimi falsi positivi \emph{anche in assenza di segnale}.

\section{Principio di Bonferroni e test multipli}\label{sec:bonferroni}
\textbf{Principio di Bonferroni.} Se il numero atteso di occorrenze dell'evento cercato (sotto l'ipotesi di casualità dei dati) è significativamente \emph{maggiore} del numero di istanze che ci si aspetta di trovare nella realtà, allora qualsiasi ``pattern'' osservato è più verosimilmente un \emph{artefatto} che non un'evidenza.
%
\paragraph{Interpretazione operativa.} Quando formuliamo molte ipotesi/ricerche sui dati (\emph{multiple testing}), è necessario \emph{correggere} il livello di significatività per tenere sotto controllo i falsi positivi. Una correzione conservativa è la \emph{correzione di Bonferroni}: se eseguiamo $m$ test, imponiamo che il $p$--value di ciascun test sia $< \alpha/m$ per mantenere il Family-Wise Error Rate al di sotto di $\alpha$.
%
\paragraph{Quando applicarlo.} In scenari esplorativi su grandi basi dati (come nel caso sopra), prima di agire sui ``pattern'' trovati occorre verificare che il loro numero sia compatibile con quanto ci si aspetterebbe per puro caso. In caso contrario, i pattern vanno trattati con sospetto e sottoposti a verifica indipendente (es.\ dati di conferma, A/B test, validazione su hold-out).

% --- Fine capitolo 1 ---