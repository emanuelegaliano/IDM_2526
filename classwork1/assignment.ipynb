{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ea79350",
   "metadata": {},
   "source": [
    "# First Classwork – Data Mining\n",
    "\n",
    "Questo notebook affronta il problema legato al primo classwork di Data Mining. Per farlo, si utilizza principalmente una libreria esterna [TRACCIA](https://github.com/emanuelegaliano/TRACCIA). Il progetto è stato suddiviso in diverse fasi che possono essere trovate all'interno del file [roadmap.md](roadmap.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32021f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting git+https://github.com/emanuelegaliano/TRACCIA.git (from -r requirements.txt (line 1))\n",
      "  Cloning https://github.com/emanuelegaliano/TRACCIA.git to /tmp/pip-req-build-dmez_hmy\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/emanuelegaliano/TRACCIA.git /tmp/pip-req-build-dmez_hmy\n",
      "  Resolved https://github.com/emanuelegaliano/TRACCIA.git to commit 4dd9ba02a86286c7e28196f8a24696279416caf0\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=2.0 in /usr/lib64/python3.14/site-packages (from -r requirements.txt (line 4)) (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.24 in /usr/lib64/python3.14/site-packages (from -r requirements.txt (line 5)) (2.3.5)\n",
      "Requirement already satisfied: matplotlib>=3.7 in /home/manu/.local/lib/python3.14/site-packages (from -r requirements.txt (line 8)) (3.10.8)\n",
      "Requirement already satisfied: mlxtend>=0.23 in /home/manu/.local/lib/python3.14/site-packages (from -r requirements.txt (line 11)) (0.24.0)\n",
      "Requirement already satisfied: scikit-learn>=1.3 in /home/manu/.local/lib/python3.14/site-packages (from -r requirements.txt (line 14)) (1.8.0)\n",
      "Requirement already satisfied: tqdm>=4.66 in /usr/lib/python3.14/site-packages (from -r requirements.txt (line 17)) (4.67.1)\n",
      "Requirement already satisfied: pytest>=7.4 in /home/manu/.local/lib/python3.14/site-packages (from -r requirements.txt (line 20)) (9.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/lib/python3.14/site-packages (from pandas>=2.0->-r requirements.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3.14/site-packages (from pandas>=2.0->-r requirements.txt (line 4)) (2025.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/lib64/python3.14/site-packages (from matplotlib>=3.7->-r requirements.txt (line 8)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/lib/python3.14/site-packages (from matplotlib>=3.7->-r requirements.txt (line 8)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/lib64/python3.14/site-packages (from matplotlib>=3.7->-r requirements.txt (line 8)) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/lib64/python3.14/site-packages (from matplotlib>=3.7->-r requirements.txt (line 8)) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/lib/python3.14/site-packages (from matplotlib>=3.7->-r requirements.txt (line 8)) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in /usr/lib64/python3.14/site-packages (from matplotlib>=3.7->-r requirements.txt (line 8)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /usr/lib/python3.14/site-packages (from matplotlib>=3.7->-r requirements.txt (line 8)) (3.1.2)\n",
      "Requirement already satisfied: scipy>=1.16.3 in /home/manu/.local/lib/python3.14/site-packages (from mlxtend>=0.23->-r requirements.txt (line 11)) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.5.2 in /home/manu/.local/lib/python3.14/site-packages (from mlxtend>=0.23->-r requirements.txt (line 11)) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/manu/.local/lib/python3.14/site-packages (from scikit-learn>=1.3->-r requirements.txt (line 14)) (3.6.0)\n",
      "Requirement already satisfied: iniconfig>=1.0.1 in /home/manu/.local/lib/python3.14/site-packages (from pytest>=7.4->-r requirements.txt (line 20)) (2.3.0)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in /usr/lib/python3.14/site-packages (from pytest>=7.4->-r requirements.txt (line 20)) (1.6.0)\n",
      "Requirement already satisfied: pygments>=2.7.2 in /usr/lib/python3.14/site-packages (from pytest>=7.4->-r requirements.txt (line 20)) (2.19.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3.14/site-packages (from python-dateutil>=2.8.2->pandas>=2.0->-r requirements.txt (line 4)) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98631b9e",
   "metadata": {},
   "source": [
    "In questa cella importiamo:\n",
    "\n",
    "- `Trail` dalla libreria **TRACCIA**, che ci permette di definire ed eseguire pipeline di elaborazione;\n",
    "- gli **step di cleaning** definiti nel modulo `cleaning.py`, che verranno concatenati nel `CLEANING_TRAIL`;\n",
    "- la classe `FirstClassworkFootprint`, che rappresenta lo stato condiviso tra tutti gli step della pipeline;\n",
    "- la dataclass `Config`, che centralizza tutti i parametri di configurazione del progetto.\n",
    "\n",
    "Questi import costituiscono la base per eseguire la **Fase B – Data Loading & Cleaning** dell’assignment.\n",
    "\n",
    "**NB**: La fase A è intrisenca all'interno del codice sorgente, per questo viene saltata in questo notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4c2317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRACCIA] Trail 'Trail' starting\n",
      "[TRACCIA] -> log_config\n",
      "[TRACCIA] -> load_dataset\n",
      "[TRACCIA] -> normalize_schema\n",
      "[TRACCIA] -> parse_datetime\n",
      "[TRACCIA] -> drop_invalid_rows\n",
      "[TRACCIA] -> exclude_shoppers\n",
      "[TRACCIA] -> add_time_bins\n",
      "[TRACCIA] -> finalize_cleaning\n",
      "[TRACCIA] Trail 'Trail' finished (handlers=['log_config', 'load_dataset', 'normalize_schema', 'parse_datetime', 'drop_invalid_rows', 'exclude_shoppers', 'add_time_bins', 'finalize_cleaning'])\n"
     ]
    }
   ],
   "source": [
    "from traccia import Trail\n",
    "from src.pipelines.cleaning import (\n",
    "    log_config,\n",
    "    load_dataset,\n",
    "    normalize_schema,\n",
    "    parse_datetime,\n",
    "    drop_invalid_rows,\n",
    "    exclude_shoppers,\n",
    "    add_time_bins,\n",
    "    finalize_cleaning,\n",
    "    CLEANING_TRAIL\n",
    ")\n",
    "from src.domain.footprint import FirstClassworkFootprint\n",
    "from src.domain.config import Config\n",
    "\n",
    "config = Config(\n",
    "    data_path=\"AnonymizedFidelity.csv\",\n",
    "    output_dir=\"outputs\",\n",
    "    date_format=\"%Y-%m-%d\",\n",
    "    time_format=None,      # se non sai ancora se c'è :SS\n",
    "    dayfirst=False         # coerente con ISO\n",
    ")\n",
    "\n",
    "fp = FirstClassworkFootprint(config=config)\n",
    "CLEANING_TRAIL.trace_enabled = True # True for debug\n",
    "\n",
    "fp = CLEANING_TRAIL.run(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191a28ac",
   "metadata": {},
   "source": [
    "## FASE B: Pipeline di cleaning\n",
    "\n",
    "In questa cella:\n",
    "\n",
    "1. Istanziamo l’oggetto `Config`, specificando:\n",
    "   - il percorso del dataset (`AnonymizedFidelity.csv`),\n",
    "   - la directory di output,\n",
    "   - il formato delle date e delle ore (deterministico, per evitare warning e ambiguità).\n",
    "\n",
    "2. Creiamo un oggetto `FirstClassworkFootprint`, che fungerà da contenitore condiviso\n",
    "   per i dati grezzi, i dati puliti e i metadata di esecuzione.\n",
    "\n",
    "3. Attiviamo la modalità `trace_enabled` sul `CLEANING_TRAIL` per visualizzare l’ordine\n",
    "   di esecuzione degli step (utile in fase di debug).\n",
    "\n",
    "4. Eseguiamo infine la pipeline di cleaning tramite il metodo `run`, ottenendo un\n",
    "   dataset pulito e pronto per le successive fasi di analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d20c177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2023-03-25', '2023-03-25', '2023-03-25', '2023-03-25', '2023-03-25', '2023-03-25', '2023-03-25', '2023-03-25', '2023-03-25', '2023-03-25']\n",
      "['21:00', '21:00', '21:00', '21:00', '21:00', '21:00', '21:00', '21:00', '21:00', '21:00']\n"
     ]
    }
   ],
   "source": [
    "print(fp.raw_df[config.col_date].astype(str).head(10).tolist())\n",
    "print(fp.raw_df[config.col_time].astype(str).head(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7128b2ea",
   "metadata": {},
   "source": [
    "## Fase C - Analisi delle frequenze (Task 1)\n",
    "\n",
    "In questa fase affrontiamo il **Task 1 dell’assignment**, che richiede di calcolare la frequenza\n",
    "degli elementi per ciascun livello della gerarchia di merchandising e di visualizzare,\n",
    "per ogni livello, i **Top-5** e **Bottom-5** elementi più frequenti.\n",
    "\n",
    "### Obiettivi\n",
    "- Calcolare le frequenze per i livelli:\n",
    "  - `liv1`\n",
    "  - `liv2`\n",
    "  - `liv3`\n",
    "  - `liv4`\n",
    "- Generare, per ogni livello, due grafici a barre:\n",
    "  - Top-5 elementi più frequenti\n",
    "  - Bottom-5 elementi meno frequenti\n",
    "- Salvare automaticamente i risultati su disco per l’inclusione nel report finale.\n",
    "\n",
    "### Approccio\n",
    "L’analisi è implementata come una **pipeline TRACCIA dedicata** (`TASK1_FREQUENCIES_TRAIL`),\n",
    "che assume come input il dataset già pulito prodotto nella Fase B.\n",
    "\n",
    "La pipeline esegue i seguenti step:\n",
    "1. Calcolo delle tabelle di frequenza per ciascun livello di merchandising.\n",
    "2. Estrazione dei Top-5 e Bottom-5 elementi.\n",
    "3. Generazione e salvataggio dei grafici a barre in formato PNG.\n",
    "\n",
    "Tutti i risultati intermedi e finali vengono memorizzati nel `Footprint`:\n",
    "- le tabelle di frequenza sono salvate in `fp.freq_tables`,\n",
    "- i percorsi dei grafici generati sono salvati in `fp.plots`.\n",
    "\n",
    "I file di output sono scritti nella directory: [outputs/task1](outputs/task1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16577bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['outputs/task1/liv1_top5.png',\n",
       " 'outputs/task1/liv1_bottom5.png',\n",
       " 'outputs/task1/liv2_top5.png',\n",
       " 'outputs/task1/liv2_bottom5.png',\n",
       " 'outputs/task1/liv3_top5.png']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.pipelines.frequencies_task1 import TASK1_FREQUENCIES_TRAIL\n",
    "\n",
    "fp = TASK1_FREQUENCIES_TRAIL.run(fp)\n",
    "\n",
    "fp.freq_tables[\"liv1\"].head()\n",
    "fp.plots[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c457b5",
   "metadata": {},
   "source": [
    "## Fase D – Analisi delle frequenze stratificate (Task 2)\n",
    "\n",
    "In questa fase affrontiamo il **Task 2 dell’assignment**, che estende l’analisi descrittiva\n",
    "del Task 1 introducendo una **stratificazione temporale** delle frequenze.\n",
    "\n",
    "L’obiettivo è analizzare come la distribuzione degli elementi nei diversi livelli\n",
    "di merchandising vari:\n",
    "- durante differenti periodi dell’anno;\n",
    "- nelle diverse fasce orarie della giornata.\n",
    "\n",
    "### Stratificazioni considerate\n",
    "\n",
    "Il dataset è stato precedentemente arricchito (Fase B) con due variabili temporali:\n",
    "\n",
    "- **`month_range`**, che suddivide l’anno in tre periodi:\n",
    "  - *Jan – mid May*\n",
    "  - *mid May – Sep*\n",
    "  - *Oct – Dec*\n",
    "\n",
    "- **`time_slot`**, che suddivide la giornata in tre fasce orarie:\n",
    "  - *08:30 – 12:30*\n",
    "  - *12:30 – 16:30*\n",
    "  - *16:30 – 20:30*\n",
    "\n",
    "(Eventuali acquisti al di fuori di queste fasce vengono etichettati come `OUTSIDE`.)\n",
    "\n",
    "### Approccio\n",
    "\n",
    "L’analisi è implementata tramite una pipeline dedicata (`TASK2_FULL_TRAIL`), che:\n",
    "1. Filtra il dataset per ciascun valore di stratificazione (`month_range` o `time_slot`);\n",
    "2. Calcola le frequenze per ciascun livello di merchandising (`liv1`–`liv4`);\n",
    "3. Estrae i **Top-5** e **Bottom-5** elementi per ogni combinazione livello–strato;\n",
    "4. Genera e salva i grafici a barre corrispondenti.\n",
    "\n",
    "Per mantenere il codice modulare e riutilizzabile, il calcolo delle frequenze e la\n",
    "generazione dei plot sfruttano funzioni comuni definite nel modulo `utilities`.\n",
    "\n",
    "### Output\n",
    "\n",
    "I risultati vengono salvati automaticamente nella directory: [outputs/task2/](outputs/task2/)\n",
    "\n",
    "\n",
    "con la seguente struttura:\n",
    "- `outputs/task2/month_range/<periodo>/`\n",
    "- `outputs/task2/time_slot/<fascia_oraria>/`\n",
    "\n",
    "Le tabelle di frequenza e i percorsi dei grafici generati sono inoltre memorizzati\n",
    "nel `Footprint`, permettendo un facile accesso ai risultati per il report finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1480dd86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRACCIA] Trail 'Trail' starting\n",
      "[TRACCIA] -> task2_month_range_frequencies_and_plots\n",
      "[TRACCIA] -> task2_time_slot_frequencies_and_plots\n",
      "[TRACCIA] Trail 'Trail' finished (handlers=['log_config', 'load_dataset', 'normalize_schema', 'parse_datetime', 'drop_invalid_rows', 'exclude_shoppers', 'add_time_bins', 'finalize_cleaning', 'task1_compute_frequencies', 'task1_plot_top_bottom', 'task2_month_range_frequencies_and_plots', 'task2_time_slot_frequencies_and_plots'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['outputs/task2/time_slot/OUTSIDE/liv2_bottom5.png',\n",
       " 'outputs/task2/time_slot/OUTSIDE/liv3_top5.png',\n",
       " 'outputs/task2/time_slot/OUTSIDE/liv3_bottom5.png',\n",
       " 'outputs/task2/time_slot/OUTSIDE/liv4_top5.png',\n",
       " 'outputs/task2/time_slot/OUTSIDE/liv4_bottom5.png']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.pipelines.frequencies_task2 import TASK2_FULL_TRAIL\n",
    "\n",
    "TASK2_FULL_TRAIL.trace_enabled = True\n",
    "fp = TASK2_FULL_TRAIL.run(fp)\n",
    "\n",
    "fp.plots[-5:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20353e5",
   "metadata": {},
   "source": [
    "## Fase E – Association Rules Mining (Task 3 & Task 4)\n",
    "\n",
    "In questa fase affrontiamo i **Task 3 e 4 dell’assignment**, che richiedono\n",
    "l’estrazione di **regole di associazione** a partire dai dati di vendita,\n",
    "utilizzando due algoritmi classici di data mining:\n",
    "\n",
    "- **Apriori**\n",
    "- **FP-Growth**\n",
    "\n",
    "L’analisi viene condotta al **livello 4 della gerarchia di merchandising (liv4)**,\n",
    "considerando ciascuno scontrino come una transazione e ciascun elemento di livello 4\n",
    "come un item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55da5d0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRACCIA] Trail 'Trail' starting\n",
      "[TRACCIA] -> build_transactions_lvl4\n",
      "[TRACCIA] -> apriori_rules\n",
      "[TRACCIA] -> fpgrowth_rules\n",
      "[TRACCIA] -> save_rules\n",
      "[TRACCIA] Trail 'Trail' finished (handlers=['log_config', 'load_dataset', 'normalize_schema', 'parse_datetime', 'drop_invalid_rows', 'exclude_shoppers', 'add_time_bins', 'finalize_cleaning', 'task1_compute_frequencies', 'task1_plot_top_bottom', 'task2_month_range_frequencies_and_plots', 'task2_time_slot_frequencies_and_plots', 'build_transactions_lvl4', 'apriori_rules', 'fpgrowth_rules', 'save_rules', 'build_transactions_lvl4', 'apriori_rules', 'fpgrowth_rules', 'save_rules'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(149410, 141)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.pipelines.association_rules import TASK3_4_FULL_TRAIL\n",
    "\n",
    "TASK3_4_FULL_TRAIL.trace_enabled = True\n",
    "fp = TASK3_4_FULL_TRAIL.run(fp)\n",
    "\n",
    "fp.transactions_lvl4.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2335fe77",
   "metadata": {},
   "source": [
    "### Preprocessing per la scalabilità\n",
    "\n",
    "A causa dell’elevata numerosità iniziale degli item di livello 4, è stato applicato\n",
    "un filtro preliminare basato sul **supporto minimo**, mantenendo solo gli item\n",
    "presenti in almeno il **2% delle transazioni** (`min_support = 0.02`).\n",
    "\n",
    "Dopo questo filtraggio, la matrice transazioni–item risulta di dimensione: (149410 transazioni, 141 item)\n",
    "\n",
    "### Parametri principali\n",
    "\n",
    "- **Supporto minimo**: 0.02  \n",
    "- **Confidenza minima**: 0.35  \n",
    "- **Lift minimo**: 1.1  \n",
    "- **Lunghezza massima delle regole**:\n",
    "  - Apriori: 2\n",
    "  - FP-Growth: fino a 3\n",
    "\n",
    "I risultati delle due tecniche vengono confrontati in termini di numero e qualità\n",
    "delle regole estratte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bb1e991",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    32.000000\n",
       "mean      0.043502\n",
       "std       0.016416\n",
       "min       0.020039\n",
       "25%       0.028315\n",
       "50%       0.043180\n",
       "75%       0.056777\n",
       "max       0.073656\n",
       "Name: support, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.rules_apriori[\"support\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b1f48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>antecedents</th>\n",
       "      <th>consequents</th>\n",
       "      <th>antecedent support</th>\n",
       "      <th>consequent support</th>\n",
       "      <th>support</th>\n",
       "      <th>confidence</th>\n",
       "      <th>lift</th>\n",
       "      <th>representativity</th>\n",
       "      <th>leverage</th>\n",
       "      <th>conviction</th>\n",
       "      <th>zhangs_metric</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>certainty</th>\n",
       "      <th>kulczynski</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>(3060404.0)</td>\n",
       "      <td>(3060405.0)</td>\n",
       "      <td>0.072458</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.024081</td>\n",
       "      <td>0.332348</td>\n",
       "      <td>4.100423</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018208</td>\n",
       "      <td>1.376388</td>\n",
       "      <td>0.815190</td>\n",
       "      <td>0.186059</td>\n",
       "      <td>0.273460</td>\n",
       "      <td>0.314729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(1150201.0)</td>\n",
       "      <td>(1150202.0)</td>\n",
       "      <td>0.137789</td>\n",
       "      <td>0.079178</td>\n",
       "      <td>0.043725</td>\n",
       "      <td>0.317336</td>\n",
       "      <td>4.007878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032815</td>\n",
       "      <td>1.348866</td>\n",
       "      <td>0.870426</td>\n",
       "      <td>0.252395</td>\n",
       "      <td>0.258636</td>\n",
       "      <td>0.434788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(1150202.0)</td>\n",
       "      <td>(1150201.0)</td>\n",
       "      <td>0.079178</td>\n",
       "      <td>0.137789</td>\n",
       "      <td>0.043725</td>\n",
       "      <td>0.552240</td>\n",
       "      <td>4.007878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032815</td>\n",
       "      <td>1.925611</td>\n",
       "      <td>0.815023</td>\n",
       "      <td>0.252395</td>\n",
       "      <td>0.480684</td>\n",
       "      <td>0.434788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>(3060404.0)</td>\n",
       "      <td>(3011512.0)</td>\n",
       "      <td>0.072458</td>\n",
       "      <td>0.134844</td>\n",
       "      <td>0.031136</td>\n",
       "      <td>0.429706</td>\n",
       "      <td>3.186698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.021365</td>\n",
       "      <td>1.517036</td>\n",
       "      <td>0.739800</td>\n",
       "      <td>0.176741</td>\n",
       "      <td>0.340820</td>\n",
       "      <td>0.330305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>(3060404.0)</td>\n",
       "      <td>(3060402.0)</td>\n",
       "      <td>0.072458</td>\n",
       "      <td>0.216592</td>\n",
       "      <td>0.048417</td>\n",
       "      <td>0.668206</td>\n",
       "      <td>3.085093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032723</td>\n",
       "      <td>2.361129</td>\n",
       "      <td>0.728658</td>\n",
       "      <td>0.201207</td>\n",
       "      <td>0.576474</td>\n",
       "      <td>0.445873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>(9010102.0)</td>\n",
       "      <td>(9010101.0)</td>\n",
       "      <td>0.100214</td>\n",
       "      <td>0.173917</td>\n",
       "      <td>0.050117</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>2.875504</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.032688</td>\n",
       "      <td>1.652496</td>\n",
       "      <td>0.724878</td>\n",
       "      <td>0.223723</td>\n",
       "      <td>0.394855</td>\n",
       "      <td>0.394133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>(9010102.0)</td>\n",
       "      <td>(9010201.0)</td>\n",
       "      <td>0.100214</td>\n",
       "      <td>0.130707</td>\n",
       "      <td>0.036363</td>\n",
       "      <td>0.362853</td>\n",
       "      <td>2.776071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.023264</td>\n",
       "      <td>1.364352</td>\n",
       "      <td>0.711034</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>0.267051</td>\n",
       "      <td>0.320527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>(3060405.0)</td>\n",
       "      <td>(3060402.0)</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.216592</td>\n",
       "      <td>0.048671</td>\n",
       "      <td>0.600495</td>\n",
       "      <td>2.772474</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.031116</td>\n",
       "      <td>1.960949</td>\n",
       "      <td>0.695699</td>\n",
       "      <td>0.195489</td>\n",
       "      <td>0.490043</td>\n",
       "      <td>0.412605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>(3060405.0)</td>\n",
       "      <td>(3011512.0)</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.134844</td>\n",
       "      <td>0.028485</td>\n",
       "      <td>0.351445</td>\n",
       "      <td>2.606314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017556</td>\n",
       "      <td>1.333975</td>\n",
       "      <td>0.670676</td>\n",
       "      <td>0.151995</td>\n",
       "      <td>0.250361</td>\n",
       "      <td>0.281346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>(3060401.0)</td>\n",
       "      <td>(3060402.0)</td>\n",
       "      <td>0.064520</td>\n",
       "      <td>0.216592</td>\n",
       "      <td>0.036122</td>\n",
       "      <td>0.559855</td>\n",
       "      <td>2.584837</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.022147</td>\n",
       "      <td>1.779885</td>\n",
       "      <td>0.655416</td>\n",
       "      <td>0.147443</td>\n",
       "      <td>0.438166</td>\n",
       "      <td>0.363315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    antecedents  consequents  antecedent support  consequent support  \\\n",
       "27  (3060404.0)  (3060405.0)            0.072458            0.081052   \n",
       "1   (1150201.0)  (1150202.0)            0.137789            0.079178   \n",
       "2   (1150202.0)  (1150201.0)            0.079178            0.137789   \n",
       "20  (3060404.0)  (3011512.0)            0.072458            0.134844   \n",
       "24  (3060404.0)  (3060402.0)            0.072458            0.216592   \n",
       "28  (9010102.0)  (9010101.0)            0.100214            0.173917   \n",
       "31  (9010102.0)  (9010201.0)            0.100214            0.130707   \n",
       "25  (3060405.0)  (3060402.0)            0.081052            0.216592   \n",
       "21  (3060405.0)  (3011512.0)            0.081052            0.134844   \n",
       "23  (3060401.0)  (3060402.0)            0.064520            0.216592   \n",
       "\n",
       "     support  confidence      lift  representativity  leverage  conviction  \\\n",
       "27  0.024081    0.332348  4.100423               1.0  0.018208    1.376388   \n",
       "1   0.043725    0.317336  4.007878               1.0  0.032815    1.348866   \n",
       "2   0.043725    0.552240  4.007878               1.0  0.032815    1.925611   \n",
       "20  0.031136    0.429706  3.186698               1.0  0.021365    1.517036   \n",
       "24  0.048417    0.668206  3.085093               1.0  0.032723    2.361129   \n",
       "28  0.050117    0.500100  2.875504               1.0  0.032688    1.652496   \n",
       "31  0.036363    0.362853  2.776071               1.0  0.023264    1.364352   \n",
       "25  0.048671    0.600495  2.772474               1.0  0.031116    1.960949   \n",
       "21  0.028485    0.351445  2.606314               1.0  0.017556    1.333975   \n",
       "23  0.036122    0.559855  2.584837               1.0  0.022147    1.779885   \n",
       "\n",
       "    zhangs_metric   jaccard  certainty  kulczynski  \n",
       "27       0.815190  0.186059   0.273460    0.314729  \n",
       "1        0.870426  0.252395   0.258636    0.434788  \n",
       "2        0.815023  0.252395   0.480684    0.434788  \n",
       "20       0.739800  0.176741   0.340820    0.330305  \n",
       "24       0.728658  0.201207   0.576474    0.445873  \n",
       "28       0.724878  0.223723   0.394855    0.394133  \n",
       "31       0.711034  0.186900   0.267051    0.320527  \n",
       "25       0.695699  0.195489   0.490043    0.412605  \n",
       "21       0.670676  0.151995   0.250361    0.281346  \n",
       "23       0.655416  0.147443   0.438166    0.363315  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp.rules_apriori.sort_values(\"lift\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "de0d10da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 51)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fp.rules_apriori), len(fp.rules_fpgrowth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274650fa",
   "metadata": {},
   "source": [
    "## Analisi e interpretazione delle regole di associazione\n",
    "\n",
    "### Dimensione dei risultati\n",
    "\n",
    "L’algoritmo di **Apriori** ha prodotto un totale di: 32 regole di aassociazione mentre FP-Growth ha individuato un numero maggiore di pattern (non riportato qui per\n",
    "brevità), confermando la sua maggiore efficienza nell’esplorazione di pattern più complessi.\n",
    "\n",
    "Le 32 regole estratte presentano metriche statistiche stabili e ben distribuite,\n",
    "come mostrato dalla distribuzione del supporto:\n",
    "- minimo: 0.020\n",
    "- massimo: 0.073\n",
    "- media: 0.043\n",
    "\n",
    "Questo indica che ogni regola è supportata da almeno il **2% degli scontrini**,\n",
    "con alcune associazioni presenti in oltre il **7% delle transazioni**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb58677",
   "metadata": {},
   "source": [
    "## Fase F – Riduzione dimensionale e clustering dei clienti (Task 5)\n",
    "\n",
    "In questa fase affrontiamo il **Task 5 dell’assignment**, con l’obiettivo di individuare\n",
    "gruppi omogenei di clienti sulla base dei loro comportamenti di acquisto.\n",
    "\n",
    "L’analisi è condotta considerando esclusivamente le transazioni associate a una\n",
    "**tessera fedeltà valida**, costruendo una matrice:\n",
    "\n",
    "- righe → tessere cliente  \n",
    "- colonne → prodotti acquistati  \n",
    "- valori → frequenza di acquisto  \n",
    "\n",
    "Data l’elevata dimensionalità della matrice risultante, viene applicata una\n",
    "**riduzione dimensionale tramite PCA (Principal Component Analysis)**, seguita\n",
    "da un algoritmo di **clustering non supervisionato**.\n",
    "\n",
    "### Pipeline adottata\n",
    "\n",
    "La pipeline implementata prevede i seguenti passaggi:\n",
    "\n",
    "1. Selezione delle sole transazioni con tessera valida;\n",
    "2. Costruzione della matrice tessera × prodotto;\n",
    "3. Standardizzazione delle feature;\n",
    "4. Applicazione della PCA, mantenendo l’80% della varianza totale;\n",
    "5. Clustering dei clienti nello spazio PCA tramite **K-Means**.\n",
    "\n",
    "Questo approccio consente di gestire un dataset di grandi dimensioni in modo\n",
    "computazionalmente sostenibile, mantenendo al contempo l’informazione rilevante\n",
    "per la segmentazione dei clienti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cab4d3f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TRACCIA] Trail 'Trail' starting\n",
      "[TRACCIA] -> filter_valid_cards\n",
      "[TRACCIA] -> build_card_product_matrix\n",
      "[TRACCIA] -> scale_matrix\n",
      "[TRACCIA] -> apply_pca\n",
      "[TRACCIA] -> cluster_cards\n",
      "[TRACCIA] -> save_task5_outputs\n",
      "[TRACCIA] Trail 'Trail' finished (handlers=['log_config', 'load_dataset', 'normalize_schema', 'parse_datetime', 'drop_invalid_rows', 'exclude_shoppers', 'add_time_bins', 'finalize_cleaning', 'task1_compute_frequencies', 'task1_plot_top_bottom', 'task2_month_range_frequencies_and_plots', 'task2_time_slot_frequencies_and_plots', 'build_transactions_lvl4', 'apriori_rules', 'fpgrowth_rules', 'save_rules', 'build_transactions_lvl4', 'apriori_rules', 'fpgrowth_rules', 'save_rules', 'filter_valid_cards', 'build_card_product_matrix', 'scale_matrix', 'apply_pca', 'cluster_cards', 'save_task5_outputs'])\n"
     ]
    }
   ],
   "source": [
    "from src.pipelines.pca_clustering import TASK5_PCA_CLUSTERING_TRAIL\n",
    "\n",
    "TASK5_PCA_CLUSTERING_TRAIL.trace_enabled = True\n",
    "fp = TASK5_PCA_CLUSTERING_TRAIL.run(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95ea0bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9375, 19422)\n",
      "{'task5_silhouette': 0.6868467882048566}\n"
     ]
    }
   ],
   "source": [
    "print(fp.card_product_matrix.shape)\n",
    "print(fp.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f567b5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calinski-Harabasz Score: 9.921387605182197\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import calinski_harabasz_score\n",
    "\n",
    "print(\"Calinski-Harabasz Score:\", calinski_harabasz_score(fp.pca_embeddings, fp.cluster_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072c05f6",
   "metadata": {},
   "source": [
    "## Analisi e interpretazione dei risultati del clustering\n",
    "\n",
    "### Dimensione del problema\n",
    "\n",
    "Dopo il preprocessing, la matrice tessera × prodotto risulta di dimensione: (9375 tessere, 19422 prodotti).\n",
    "\n",
    "Si tratta di un dataset ad **alta dimensionalità**, tipico di contesti retail reali,\n",
    "caratterizzato da dati sparsi e fortemente sbilanciati.\n",
    "\n",
    "### Riduzione dimensionale (PCA)\n",
    "\n",
    "L’applicazione della PCA ha consentito di ridurre significativamente la dimensionalità\n",
    "del problema, mantenendo l’80% della varianza totale con: 1739 componenti principali.\n",
    "\n",
    "\n",
    "Questo rappresenta una riduzione di oltre il **90% delle feature originali**,\n",
    "rendendo possibile l’applicazione efficace di algoritmi di clustering.\n",
    "\n",
    "### Clustering\n",
    "\n",
    "Il clustering è stato eseguito utilizzando **K-Means** nello spazio ridotto dalla PCA,\n",
    "con un numero di cluster prefissato pari a 5.\n",
    "\n",
    "La qualità della partizione è stata valutata tramite il **silhouette score**, che\n",
    "assume il valore: 0.69.\n",
    "\n",
    "\n",
    "Un valore di silhouette così elevato indica una **buona separazione tra i cluster**\n",
    "e una struttura ben definita dei gruppi individuati, nonostante la complessità e\n",
    "l’eterogeneità dei dati di partenza.\n",
    "\n",
    "### Considerazioni sulla visualizzazione\n",
    "\n",
    "La proiezione dei dati in due dimensioni (ad esempio sulle prime componenti principali\n",
    "o tramite tecniche di embedding) non mostra una separazione netta dei cluster e pertanto non è stata fatta. \n",
    "\n",
    "Questo comportamento è atteso in presenza di dati ad alta dimensionalità, in cui la\n",
    "struttura discriminante dei cluster risulta distribuita su un numero elevato di componenti\n",
    "e non può essere efficacemente rappresentata in uno spazio bidimensionale senza perdita\n",
    "significativa di informazione.\n",
    "\n",
    "La qualità del clustering è stata quindi valutata principalmente attraverso **metriche\n",
    "quantitative**, in particolare il **Calinski–Harabasz Score**, che assume nel nostro caso\n",
    "il valore: Calinski–Harabasz Score = 9.92.\n",
    "\n",
    "Un valore elevato di questa metrica indica un buon rapporto tra la dispersione\n",
    "inter-cluster e quella intra-cluster, confermando la presenza di gruppi ben separati\n",
    "nello spazio delle componenti principali, nonostante la separazione non sia facilmente\n",
    "osservabile tramite proiezioni bidimensionali."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
